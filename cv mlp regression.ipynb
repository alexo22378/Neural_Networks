{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from time import time\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "#gpu memory growth fix\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "train_data = pd.read_csv('E:/Python/data/House prices/train.csv')\n",
    "train_data\n",
    "test_data = pd.read_csv('E:/Python/data/House prices/test.csv')\n",
    "test_data\n",
    "# fill na\n",
    "str_cols = train_data.select_dtypes(include=['object']).columns\n",
    "train_data.loc[:, str_cols] = train_data.loc[:, str_cols].fillna('None')\n",
    "str_cols = test_data.select_dtypes(include=['object']).columns\n",
    "test_data.loc[:, str_cols] = test_data.loc[:, str_cols].fillna('None')\n",
    "train_data = train_data.fillna(train_data.median(axis=0))\n",
    "test_data = test_data.fillna(test_data.median(axis=0))\n",
    "# train and test split\n",
    "train_X, train_y = train_data.values[:, 1:-1], train_data.values[:, -1]\n",
    "test_X = test_data.values[:, 1:]\n",
    "# One hot encoding\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "train_X_enc = enc.fit_transform(train_X)\n",
    "test_X_enc = enc.transform(test_X)\n",
    "# change type of data for nn to work\n",
    "train_X_enc=np.asarray(train_X_enc).astype(np.float32)\n",
    "train_y_enc=np.asarray(train_y).astype(np.float32)\n",
    "test_X_enc=np.asarray(test_X_enc).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 2/40 [>.............................] - ETA: 24s - loss: 120.1695WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0093s vs `on_train_batch_end` time: 1.2757s). Check your callbacks.\n",
      "40/40 [==============================] - ETA: 0s - loss: 33.2368\n",
      "Epoch 00001: val_loss improved from inf to 15.94839, saving model to best_model.h5\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 33.2368 - val_loss: 15.9484\n",
      "Epoch 2/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 15.0959\n",
      "Epoch 00002: val_loss improved from 15.94839 to 12.39519, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 15.0959 - val_loss: 12.3952\n",
      "Epoch 3/1000\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 11.1503\n",
      "Epoch 00003: val_loss improved from 12.39519 to 9.43003, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 11.1109 - val_loss: 9.4300\n",
      "Epoch 4/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8.6390\n",
      "Epoch 00004: val_loss improved from 9.43003 to 7.42318, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 8.6390 - val_loss: 7.4232\n",
      "Epoch 5/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 7.0366\n",
      "Epoch 00005: val_loss improved from 7.42318 to 6.00949, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 7.0366 - val_loss: 6.0095\n",
      "Epoch 6/1000\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 5.8706\n",
      "Epoch 00006: val_loss improved from 6.00949 to 4.98356, saving model to best_model.h5\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 5.8729 - val_loss: 4.9836\n",
      "Epoch 7/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 4.8800\n",
      "Epoch 00007: val_loss improved from 4.98356 to 4.16356, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 4.8810 - val_loss: 4.1636\n",
      "Epoch 8/1000\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 4.1772\n",
      "Epoch 00008: val_loss improved from 4.16356 to 3.54082, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 4.1781 - val_loss: 3.5408\n",
      "Epoch 9/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.6437\n",
      "Epoch 00009: val_loss improved from 3.54082 to 3.04133, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 3.6437 - val_loss: 3.0413\n",
      "Epoch 10/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 3.1979\n",
      "Epoch 00010: val_loss improved from 3.04133 to 2.63157, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 3.1954 - val_loss: 2.6316\n",
      "Epoch 11/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 2.7830\n",
      "Epoch 00011: val_loss improved from 2.63157 to 2.29401, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 2.7830 - val_loss: 2.2940\n",
      "Epoch 12/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 2.4289\n",
      "Epoch 00012: val_loss improved from 2.29401 to 2.01055, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 2.4289 - val_loss: 2.0105\n",
      "Epoch 13/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 2.1781\n",
      "Epoch 00013: val_loss improved from 2.01055 to 1.78273, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 2.1781 - val_loss: 1.7827\n",
      "Epoch 14/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.9545\n",
      "Epoch 00014: val_loss improved from 1.78273 to 1.57790, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 1.9545 - val_loss: 1.5779\n",
      "Epoch 15/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.7331\n",
      "Epoch 00015: val_loss improved from 1.57790 to 1.39349, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 1.7317 - val_loss: 1.3935\n",
      "Epoch 16/1000\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 1.5739\n",
      "Epoch 00016: val_loss improved from 1.39349 to 1.24938, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 1.5749 - val_loss: 1.2494\n",
      "Epoch 17/1000\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 1.4221\n",
      "Epoch 00017: val_loss improved from 1.24938 to 1.11696, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 1.4168 - val_loss: 1.1170\n",
      "Epoch 18/1000\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 1.3142\n",
      "Epoch 00018: val_loss improved from 1.11696 to 1.00127, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 1.3061 - val_loss: 1.0013\n",
      "Epoch 19/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 1.1707\n",
      "Epoch 00019: val_loss improved from 1.00127 to 0.89851, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 32ms/step - loss: 1.1689 - val_loss: 0.8985\n",
      "Epoch 20/1000\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 1.0805\n",
      "Epoch 00020: val_loss improved from 0.89851 to 0.81121, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 32ms/step - loss: 1.0862 - val_loss: 0.8112\n",
      "Epoch 21/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.9592\n",
      "Epoch 00021: val_loss improved from 0.81121 to 0.72742, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.9592 - val_loss: 0.7274\n",
      "Epoch 22/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.9222\n",
      "Epoch 00022: val_loss improved from 0.72742 to 0.66141, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.9222 - val_loss: 0.6614\n",
      "Epoch 23/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.8279\n",
      "Epoch 00023: val_loss improved from 0.66141 to 0.59305, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 0.8289 - val_loss: 0.5930\n",
      "Epoch 24/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.7628\n",
      "Epoch 00024: val_loss improved from 0.59305 to 0.53529, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 32ms/step - loss: 0.7623 - val_loss: 0.5353\n",
      "Epoch 25/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7121\n",
      "Epoch 00025: val_loss improved from 0.53529 to 0.48657, saving model to best_model.h5\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.7121 - val_loss: 0.4866\n",
      "Epoch 26/1000\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 0.6605- ETA: 0s - loss: 0.66\n",
      "Epoch 00026: val_loss improved from 0.48657 to 0.43677, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 32ms/step - loss: 0.6515 - val_loss: 0.4368\n",
      "Epoch 27/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.5910\n",
      "Epoch 00027: val_loss improved from 0.43677 to 0.40341, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.5913 - val_loss: 0.4034\n",
      "Epoch 28/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.5686\n",
      "Epoch 00028: val_loss improved from 0.40341 to 0.36545, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 0.5686 - val_loss: 0.3655\n",
      "Epoch 29/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.5051\n",
      "Epoch 00029: val_loss improved from 0.36545 to 0.32700, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.5044 - val_loss: 0.3270\n",
      "Epoch 30/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.4589\n",
      "Epoch 00030: val_loss improved from 0.32700 to 0.29931, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.4589 - val_loss: 0.2993\n",
      "Epoch 31/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.4361\n",
      "Epoch 00031: val_loss improved from 0.29931 to 0.27307, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.4361 - val_loss: 0.2731\n",
      "Epoch 32/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.4329\n",
      "Epoch 00032: val_loss improved from 0.27307 to 0.25189, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 0.4327 - val_loss: 0.2519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.4072\n",
      "Epoch 00033: val_loss improved from 0.25189 to 0.23184, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.4074 - val_loss: 0.2318\n",
      "Epoch 34/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3624\n",
      "Epoch 00034: val_loss improved from 0.23184 to 0.21474, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 0.3627 - val_loss: 0.2147\n",
      "Epoch 35/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3565\n",
      "Epoch 00035: val_loss improved from 0.21474 to 0.18757, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.3565 - val_loss: 0.1876\n",
      "Epoch 36/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3208\n",
      "Epoch 00036: val_loss improved from 0.18757 to 0.17617, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 32ms/step - loss: 0.3208 - val_loss: 0.1762\n",
      "Epoch 37/1000\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 0.3157\n",
      "Epoch 00037: val_loss improved from 0.17617 to 0.16415, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.3149 - val_loss: 0.1642\n",
      "Epoch 38/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2852\n",
      "Epoch 00038: val_loss improved from 0.16415 to 0.15238, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.2852 - val_loss: 0.1524\n",
      "Epoch 39/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2811\n",
      "Epoch 00039: val_loss improved from 0.15238 to 0.14140, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.2811 - val_loss: 0.1414\n",
      "Epoch 40/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2655\n",
      "Epoch 00040: val_loss improved from 0.14140 to 0.14101, saving model to best_model.h5\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.2655 - val_loss: 0.1410\n",
      "Epoch 41/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2327\n",
      "Epoch 00041: val_loss improved from 0.14101 to 0.12750, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2327 - val_loss: 0.1275\n",
      "Epoch 42/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2370\n",
      "Epoch 00042: val_loss improved from 0.12750 to 0.11336, saving model to best_model.h5\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.2375 - val_loss: 0.1134\n",
      "Epoch 43/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2232\n",
      "Epoch 00043: val_loss improved from 0.11336 to 0.10552, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2227 - val_loss: 0.1055\n",
      "Epoch 44/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2004\n",
      "Epoch 00044: val_loss improved from 0.10552 to 0.09989, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.2004 - val_loss: 0.0999\n",
      "Epoch 45/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2238\n",
      "Epoch 00045: val_loss improved from 0.09989 to 0.09258, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.2238 - val_loss: 0.0926\n",
      "Epoch 46/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1949\n",
      "Epoch 00046: val_loss improved from 0.09258 to 0.08514, saving model to best_model.h5\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.1956 - val_loss: 0.0851\n",
      "Epoch 47/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1936\n",
      "Epoch 00047: val_loss improved from 0.08514 to 0.08055, saving model to best_model.h5\n",
      "40/40 [==============================] - 3s 84ms/step - loss: 0.1933 - val_loss: 0.0805\n",
      "Epoch 48/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1789\n",
      "Epoch 00048: val_loss improved from 0.08055 to 0.07620, saving model to best_model.h5\n",
      "40/40 [==============================] - 2s 50ms/step - loss: 0.1789 - val_loss: 0.0762\n",
      "Epoch 49/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1773\n",
      "Epoch 00049: val_loss improved from 0.07620 to 0.07606, saving model to best_model.h5\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.1771 - val_loss: 0.0761\n",
      "Epoch 50/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1735\n",
      "Epoch 00050: val_loss improved from 0.07606 to 0.07203, saving model to best_model.h5\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.1735 - val_loss: 0.0720\n",
      "Epoch 51/1000\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 0.1551\n",
      "Epoch 00051: val_loss improved from 0.07203 to 0.06826, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.1545 - val_loss: 0.0683\n",
      "Epoch 52/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1629\n",
      "Epoch 00052: val_loss improved from 0.06826 to 0.06482, saving model to best_model.h5\n",
      "40/40 [==============================] - 5s 116ms/step - loss: 0.1629 - val_loss: 0.0648\n",
      "Epoch 53/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1636\n",
      "Epoch 00053: val_loss improved from 0.06482 to 0.06425, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.1636 - val_loss: 0.0643\n",
      "Epoch 54/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1485\n",
      "Epoch 00054: val_loss improved from 0.06425 to 0.06194, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.1489 - val_loss: 0.0619\n",
      "Epoch 55/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1509\n",
      "Epoch 00055: val_loss improved from 0.06194 to 0.06130, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.1509 - val_loss: 0.0613\n",
      "Epoch 56/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1476\n",
      "Epoch 00056: val_loss improved from 0.06130 to 0.05847, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 0.1477 - val_loss: 0.0585\n",
      "Epoch 57/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1459\n",
      "Epoch 00057: val_loss improved from 0.05847 to 0.05840, saving model to best_model.h5\n",
      "40/40 [==============================] - 7s 186ms/step - loss: 0.1459 - val_loss: 0.0584\n",
      "Epoch 58/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1453\n",
      "Epoch 00058: val_loss improved from 0.05840 to 0.05533, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.1450 - val_loss: 0.0553\n",
      "Epoch 59/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1322\n",
      "Epoch 00059: val_loss did not improve from 0.05533\n",
      "40/40 [==============================] - 1s 32ms/step - loss: 0.1322 - val_loss: 0.0555\n",
      "Epoch 60/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1501\n",
      "Epoch 00060: val_loss improved from 0.05533 to 0.05414, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 0.1501 - val_loss: 0.0541\n",
      "Epoch 61/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1455\n",
      "Epoch 00061: val_loss improved from 0.05414 to 0.05260, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 0.1455 - val_loss: 0.0526\n",
      "Epoch 62/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1317- ETA: 1\n",
      "Epoch 00062: val_loss improved from 0.05260 to 0.05046, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.1316 - val_loss: 0.0505\n",
      "Epoch 63/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1297\n",
      "Epoch 00063: val_loss improved from 0.05046 to 0.04981, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.1296 - val_loss: 0.0498\n",
      "Epoch 64/1000\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 0.1270\n",
      "Epoch 00064: val_loss did not improve from 0.04981\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.1267 - val_loss: 0.0499\n",
      "Epoch 65/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1193\n",
      "Epoch 00065: val_loss improved from 0.04981 to 0.04948, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 0.1193 - val_loss: 0.0495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1200\n",
      "Epoch 00066: val_loss improved from 0.04948 to 0.04896, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.1198 - val_loss: 0.0490\n",
      "Epoch 67/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1079\n",
      "Epoch 00067: val_loss improved from 0.04896 to 0.04882, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 0.1078 - val_loss: 0.0488\n",
      "Epoch 68/1000\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 0.1100- ETA: 1s -\n",
      "Epoch 00068: val_loss improved from 0.04882 to 0.04878, saving model to best_model.h5\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 0.1096 - val_loss: 0.0488\n",
      "Epoch 69/1000\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1077\n",
      "Epoch 00069: val_loss improved from 0.04878 to 0.04814, saving model to best_model.h5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b3b8bbed0707>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# fit model and save the best\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     history = model.fit(x=train_X, y=train_y, \n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;31m#                         steps_per_epoch=steps_per_epoch,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1137\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1138\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m         \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1249\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1299\u001b[0m                     filepath, overwrite=True, options=self._options)\n\u001b[0;32m   1300\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m   1976\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1977\u001b[0m     \"\"\"\n\u001b[1;32m-> 1978\u001b[1;33m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0m\u001b[0;32m   1979\u001b[0m                     signatures, options)\n\u001b[0;32m   1980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m    128\u001b[0m           \u001b[1;34m'to the Tensorflow SavedModel format (by setting save_format=\"tf\") '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m           'or using `save_weights`.')\n\u001b[1;32m--> 130\u001b[1;33m     hdf5_format.save_model_to_hdf5(\n\u001b[0m\u001b[0;32m    131\u001b[0m         model, filepath, overwrite, include_optimizer)\n\u001b[0;32m    132\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[0mmodel_weights_group\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mmodel_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m     \u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_weights_group\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;31m# TODO(b/128683857): Add integration tests between tf.keras and external\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_weights_to_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_legacy_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m     \u001b[0mweight_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m     \u001b[0mweight_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m     \u001b[0msave_attributes_to_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weight_names'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m   3516\u001b[0m   \"\"\"\n\u001b[0;32m   3517\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3518\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3519\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3520\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3516\u001b[0m   \"\"\"\n\u001b[0;32m   3517\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3518\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3519\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3520\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    606\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    610\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \"\"\"\n\u001b[0;32m   1062\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1027\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import scipy\n",
    "first_col = True\n",
    "cross_fold = KFold(n_splits = 7, shuffle=True)\n",
    "for train_index, test_index in cross_fold.split(train_X_enc):\n",
    "    validation_X, validation_y = train_X_enc[test_index], train_y_enc[test_index]\n",
    "    train_X, train_y = train_X_enc[train_index], train_y_enc[train_index]\n",
    "    \n",
    "    # determine the number of input features\n",
    "    n_features = train_X_enc.shape[1]\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(512, kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('elu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(128, kernel_initializer='he_normal'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('elu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1))\n",
    "    # compile the model\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=0.5, \\\n",
    "        beta_1=0.9, beta_2=0.999, epsilon=1e-08), loss='msle')\n",
    "    #callbacks\n",
    "    # simple early stopping\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', min_delta=0.0001, verbose=1, patience=20)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "    \n",
    "    rlrop = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=5, verbose=1)\n",
    "    \n",
    "    # fit model and save the best\n",
    "    history = model.fit(x=train_X, y=train_y, \n",
    "#                         steps_per_epoch=steps_per_epoch, \n",
    "                        batch_size=32, \n",
    "                        epochs=1000, \n",
    "                        validation_data=(validation_X, validation_y), \n",
    "#                         validation_steps=validation_steps, \n",
    "                        shuffle=True, \n",
    "                        callbacks=[tensorboard, es, mc, rlrop]\n",
    "                       )\n",
    "    saved_model = load_model('best_model.h5')\n",
    "    \n",
    "    predict = saved_model.predict(test_X_enc)\n",
    "#     predict = probs.argmax(axis=1)\n",
    "    if first_col:\n",
    "        pr_values = np.array(predict, ndmin=2)\n",
    "        pr_values = np.transpose(pr_values)\n",
    "        first_col = False\n",
    "    else:\n",
    "        pr_values = np.insert(pr_values, -1, predict, axis=1)\n",
    "pr_values= np.mean(pr_values, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
