{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "#gpu memory growth fix\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "train_data = pd.read_csv('E:\\Python\\data\\Titanic\\prs_train.csv')\n",
    "train_data\n",
    "test_data = pd.read_csv('E:\\Python\\data\\Titanic\\prs_test.csv')\n",
    "test_data\n",
    "# train and test split\n",
    "train_X, train_y = train_data.values[:, 2:], train_data.values[:, 1]\n",
    "test_X = test_data.values[:, 1:]\n",
    "# One hot encoding\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "train_X_enc = enc.fit_transform(train_X)\n",
    "test_X_enc = enc.transform(test_X)\n",
    "# change type of data for nn to work\n",
    "train_X_enc=np.asarray(train_X_enc).astype(np.float32)\n",
    "train_y=np.asarray(train_y).astype(np.float32)\n",
    "test_X_enc=np.asarray(test_X_enc).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 2/56 [>.............................] - ETA: 30s - loss: 0.9148 - accuracy: 0.4688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 1.1193s). Check your callbacks.\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 0.7667 - accuracy: 0.5939\n",
      "Epoch 2/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.6633 - accuracy: 0.6704\n",
      "Epoch 3/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5563 - accuracy: 0.7233\n",
      "Epoch 4/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.5530 - accuracy: 0.7379\n",
      "Epoch 5/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.5591 - accuracy: 0.7402\n",
      "Epoch 6/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.5067 - accuracy: 0.7683\n",
      "Epoch 7/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5150 - accuracy: 0.7728\n",
      "Epoch 8/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.7739\n",
      "Epoch 9/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.8020\n",
      "Epoch 10/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.4771 - accuracy: 0.8009\n",
      "Epoch 11/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.4488 - accuracy: 0.8031\n",
      "Epoch 12/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.8200\n",
      "Epoch 13/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.8178\n",
      "Epoch 14/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.4032 - accuracy: 0.8245\n",
      "Epoch 15/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8268\n",
      "Epoch 16/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.8459\n",
      "Epoch 17/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.8335\n",
      "Epoch 18/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.3529 - accuracy: 0.8673\n",
      "Epoch 19/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.3716 - accuracy: 0.8414\n",
      "Epoch 20/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.3718 - accuracy: 0.8549\n",
      "Epoch 21/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.3496 - accuracy: 0.8774\n",
      "Epoch 22/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.3581 - accuracy: 0.8673\n",
      "Epoch 23/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.3388 - accuracy: 0.8740\n",
      "Epoch 24/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.3369 - accuracy: 0.8616\n",
      "Epoch 25/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.3455 - accuracy: 0.8673\n",
      "Epoch 26/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.3172 - accuracy: 0.8853\n",
      "Epoch 27/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.3255 - accuracy: 0.8886\n",
      "Epoch 28/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.3273 - accuracy: 0.8808\n",
      "Epoch 29/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.3059 - accuracy: 0.8898\n",
      "Epoch 30/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.3373 - accuracy: 0.8684\n",
      "Epoch 31/100\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.3113 - accuracy: 0.8819\n",
      "Epoch 32/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.3042 - accuracy: 0.8796\n",
      "Epoch 33/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.3087 - accuracy: 0.8819\n",
      "Epoch 34/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2960 - accuracy: 0.8853\n",
      "Epoch 35/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.3084 - accuracy: 0.8853\n",
      "Epoch 36/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.3095 - accuracy: 0.8886\n",
      "Epoch 37/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.3305 - accuracy: 0.8954\n",
      "Epoch 38/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2836 - accuracy: 0.9055\n",
      "Epoch 39/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.3073 - accuracy: 0.8785\n",
      "Epoch 40/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.3021 - accuracy: 0.8898\n",
      "Epoch 41/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2967 - accuracy: 0.8898\n",
      "Epoch 42/100\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.2764 - accuracy: 0.89 - 0s 6ms/step - loss: 0.2774 - accuracy: 0.8976\n",
      "Epoch 43/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2980 - accuracy: 0.8774\n",
      "Epoch 44/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2986 - accuracy: 0.8920\n",
      "Epoch 45/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2781 - accuracy: 0.8943\n",
      "Epoch 46/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2696 - accuracy: 0.9021\n",
      "Epoch 47/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.3005 - accuracy: 0.8999\n",
      "Epoch 48/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2847 - accuracy: 0.8931\n",
      "Epoch 49/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2918 - accuracy: 0.9033\n",
      "Epoch 50/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2976 - accuracy: 0.8920\n",
      "Epoch 51/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.2702 - accuracy: 0.9044\n",
      "Epoch 52/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2718 - accuracy: 0.9089\n",
      "Epoch 53/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2752 - accuracy: 0.9021\n",
      "Epoch 54/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2986 - accuracy: 0.8819\n",
      "Epoch 55/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2857 - accuracy: 0.8763: 0s - loss: 0.3056 - accura\n",
      "Epoch 56/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2767 - accuracy: 0.8965\n",
      "Epoch 57/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2817 - accuracy: 0.9010\n",
      "Epoch 58/100\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.2689 - accuracy: 0.88 - 0s 6ms/step - loss: 0.2708 - accuracy: 0.8864\n",
      "Epoch 59/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2674 - accuracy: 0.9010\n",
      "Epoch 60/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2703 - accuracy: 0.8988\n",
      "Epoch 61/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2637 - accuracy: 0.9033\n",
      "Epoch 62/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2632 - accuracy: 0.9021\n",
      "Epoch 63/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2889 - accuracy: 0.8920\n",
      "Epoch 64/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2740 - accuracy: 0.9044\n",
      "Epoch 65/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2393 - accuracy: 0.9089\n",
      "Epoch 66/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2760 - accuracy: 0.8920\n",
      "Epoch 67/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2548 - accuracy: 0.9201\n",
      "Epoch 68/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2595 - accuracy: 0.9089\n",
      "Epoch 69/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.2597 - accuracy: 0.9089\n",
      "Epoch 70/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.2655 - accuracy: 0.9066\n",
      "Epoch 71/100\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.2516 - accuracy: 0.8988\n",
      "Epoch 72/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.2594 - accuracy: 0.9010\n",
      "Epoch 73/100\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 0.2541 - accuracy: 0.9123\n",
      "Epoch 74/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.2585 - accuracy: 0.9089\n",
      "Epoch 75/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.2536 - accuracy: 0.9134\n",
      "Epoch 76/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.2660 - accuracy: 0.9033\n",
      "Epoch 77/100\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 0.2569 - accuracy: 0.9033\n",
      "Epoch 78/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.2490 - accuracy: 0.9089\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 7ms/step - loss: 0.2351 - accuracy: 0.9156\n",
      "Epoch 80/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.2811 - accuracy: 0.8965\n",
      "Epoch 81/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2774 - accuracy: 0.8965\n",
      "Epoch 82/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2365 - accuracy: 0.9134\n",
      "Epoch 83/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2367 - accuracy: 0.9168\n",
      "Epoch 84/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2888 - accuracy: 0.8954\n",
      "Epoch 85/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2492 - accuracy: 0.9021\n",
      "Epoch 86/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2387 - accuracy: 0.9033\n",
      "Epoch 87/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.2579 - accuracy: 0.9033\n",
      "Epoch 88/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2478 - accuracy: 0.9145\n",
      "Epoch 89/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2452 - accuracy: 0.9021\n",
      "Epoch 90/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2664 - accuracy: 0.9044\n",
      "Epoch 91/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2482 - accuracy: 0.8988: 0s - loss: 0.2879 - accuracy\n",
      "Epoch 92/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2366 - accuracy: 0.9089\n",
      "Epoch 93/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2354 - accuracy: 0.9033\n",
      "Epoch 94/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2668 - accuracy: 0.9089\n",
      "Epoch 95/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.2599 - accuracy: 0.8999\n",
      "Epoch 96/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2740 - accuracy: 0.9021\n",
      "Epoch 97/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2132 - accuracy: 0.9235\n",
      "Epoch 98/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2364 - accuracy: 0.9145\n",
      "Epoch 99/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2409 - accuracy: 0.9123\n",
      "Epoch 100/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2270 - accuracy: 0.9201\n"
     ]
    }
   ],
   "source": [
    "# determine the number of input features\n",
    "n_features = train_X_enc.shape[1]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(50, kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('elu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(40, kernel_initializer='he_normal'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('elu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "#callbacks\n",
    "# simple early stopping\n",
    "# es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=TOL, verbose=VERBOSE, patience=N_ITER_NO_CHANGE)\n",
    "# mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=VERBOSE, save_best_only=True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "# fit the model\n",
    "model.fit(train_X_enc, train_y, epochs=100, batch_size=16, callbacks=[tensorboard,])\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = zip(test_data.iloc[:, 0],np.argmax(yhat, axis=1))\n",
    "data3 = pd.DataFrame(z, columns=['PassengerId', 'Survived'])\n",
    "data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results\n",
    "data3.to_csv('E:/Python/data/Titanic/gender_submission10.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
