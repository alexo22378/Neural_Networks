{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     # Restrict TensorFlow to only use the first GPU\n",
    "#     try:\n",
    "#         tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "#         logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "#     except RuntimeError as e:\n",
    "#         # Visible devices must be set before GPUs have been initialized\n",
    "#         print(e)\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "BATCH_SIZE = 16\n",
    "TOL = 0.0001\n",
    "N_ITER_NO_CHANGE = 30\n",
    "VERBOSE = 1\n",
    "MAX_EPOCHS = 200\n",
    "VALIDATION_FRACTION = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape: (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# loading train and test, creating validation\n",
    "data1 = pd.read_csv('E:/Python/data/digits/train.csv')\n",
    "data2 = pd.read_csv('E:/Python/data/digits/test.csv')\n",
    "train = {}\n",
    "test = {}\n",
    "train['features'] = data1.iloc[:,1:]\n",
    "train['labels'] = data1.iloc[:,:1]\n",
    "train['features'] = np.expand_dims(train['features'], axis=(1, 0))\n",
    "train['features'] = np.reshape(train['features'], (-1, 28, 28, 1))\n",
    "test['features'] = data2\n",
    "test['features'] = np.expand_dims(test['features'], axis=(1, 0))\n",
    "test['features'] = np.reshape(test['features'], (-1, 28, 28, 1))\n",
    "print(\"Image Shape: {}\".format(train['features'][0].shape))\n",
    "validation = {}\n",
    "train['features'], validation['features'], train['labels'], validation['labels'] = \\\n",
    "    train_test_split(train['features'], train['labels'], test_size=VALIDATION_FRACTION, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Image Shape: (32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Pad images with 0s\n",
    "train['features']      = np.pad(train['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "validation['features'] = np.pad(validation['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "test['features']       = np.pad(test['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "    \n",
    "print(\"Updated Image Shape: {}\".format(train['features'][0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ebc4601343c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# model itself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "# model itself\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), input_shape=(32,32,1)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Dense(units=120))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('elu'))\n",
    "\n",
    "model.add(layers.Dense(units=84))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Dropout(0.33))\n",
    "\n",
    "model.add(layers.Dense(units=30))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('elu'))\n",
    "\n",
    "model.add(layers.Dropout(0.33))\n",
    "\n",
    "model.add(layers.Dense(units=10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(lr=0.001, \\\n",
    "    beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.SGD(), metrics=['accuracy'])\n",
    "\n",
    "# simple early stopping\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=TOL, verbose=VERBOSE, patience=N_ITER_NO_CHANGE)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=VERBOSE, save_best_only=True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "   2/1050 [..............................] - ETA: 26:54 - loss: 2.5913 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0150s vs `on_train_batch_end` time: 3.0632s). Check your callbacks.\n",
      "1047/1050 [============================>.] - ETA: 0s - loss: 0.3758 - accuracy: 0.8985 ETA: 0s - loss: 0\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.97209, saving model to best_model.h5\n",
      "1050/1050 [==============================] - 20s 19ms/step - loss: 0.3751 - accuracy: 0.8986 - val_loss: 0.0909 - val_accuracy: 0.9721\n",
      "Epoch 2/200\n",
      "1049/1050 [============================>.] - ETA: 0s - loss: 0.1491 - accuracy: 0.9573\n",
      "Epoch 00002: val_accuracy improved from 0.97209 to 0.97746, saving model to best_model.h5\n",
      "1050/1050 [==============================] - 15s 15ms/step - loss: 0.1491 - accuracy: 0.9572 - val_loss: 0.0697 - val_accuracy: 0.9775\n",
      "Epoch 3/200\n",
      "1050/1050 [==============================] - ETA: 0s - loss: 0.1173 - accuracy: 0.9658\n",
      "Epoch 00003: val_accuracy improved from 0.97746 to 0.97865, saving model to best_model.h5\n",
      "1050/1050 [==============================] - 16s 15ms/step - loss: 0.1173 - accuracy: 0.9658 - val_loss: 0.0721 - val_accuracy: 0.9786\n",
      "Epoch 4/200\n",
      "1050/1050 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9715\n",
      "Epoch 00004: val_accuracy improved from 0.97865 to 0.97901, saving model to best_model.h5\n",
      "1050/1050 [==============================] - 16s 15ms/step - loss: 0.1018 - accuracy: 0.9715 - val_loss: 0.0730 - val_accuracy: 0.9790\n",
      "Epoch 5/200\n",
      " 939/1050 [=========================>....] - ETA: 1s - loss: 0.0871 - accuracy: 0.9745"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-806f6263ffe4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# fit model and save the best\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=MAX_EPOCHS, \n\u001b[0m\u001b[0;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     shuffle=True, callbacks=[tensorboard, es, mc])\n\u001b[0;32m      5\u001b[0m \u001b[0msaved_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit model and save the best\n",
    "history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=MAX_EPOCHS, \n",
    "                    validation_data=validation_generator, validation_steps=validation_steps, \n",
    "                    shuffle=True, callbacks=[tensorboard, es, mc])\n",
    "saved_model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape: (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# loading train and test, creating validation\n",
    "data1 = pd.read_csv('E:/Python/data/digits/train.csv')\n",
    "data2 = pd.read_csv('E:/Python/data/digits/test.csv')\n",
    "train = {}\n",
    "test = {}\n",
    "train['features'] = data1.iloc[:,1:]\n",
    "train['labels'] = data1.iloc[:,:1]\n",
    "train['features'] = np.expand_dims(train['features'], axis=(1, 0))\n",
    "train['features'] = np.reshape(train['features'], (-1, 28, 28, 1))\n",
    "test['features'] = data2\n",
    "test['features'] = np.expand_dims(test['features'], axis=(1, 0))\n",
    "test['features'] = np.reshape(test['features'], (-1, 28, 28, 1))\n",
    "print(\"Image Shape: {}\".format(train['features'][0].shape))\n",
    "validation = {}\n",
    "\n",
    "# Pad images with 0s\n",
    "train['features']      = np.pad(train['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "test['features']       = np.pad(test['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "   2/2100 [..............................] - ETA: 54:16 - loss: 2.7181 - accuracy: 0.1562 WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0215s vs `on_train_batch_end` time: 3.0788s). Check your callbacks.\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.4855 - accuracy: 0.8572\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.97143, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 31s 15ms/step - loss: 0.4854 - accuracy: 0.8572 - val_loss: 0.0934 - val_accuracy: 0.9714\n",
      "Epoch 2/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.2410 - accuracy: 0.9336\n",
      "Epoch 00002: val_accuracy improved from 0.97143 to 0.97940, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.2408 - accuracy: 0.9337 - val_loss: 0.0687 - val_accuracy: 0.9794\n",
      "Epoch 3/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.1902 - accuracy: 0.9473\n",
      "Epoch 00003: val_accuracy did not improve from 0.97940\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.1902 - accuracy: 0.9473 - val_loss: 0.0804 - val_accuracy: 0.9754\n",
      "Epoch 4/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.1742 - accuracy: 0.9523\n",
      "Epoch 00004: val_accuracy improved from 0.97940 to 0.98464, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.1740 - accuracy: 0.9524 - val_loss: 0.0498 - val_accuracy: 0.9846\n",
      "Epoch 5/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.1462 - accuracy: 0.9596\n",
      "Epoch 00005: val_accuracy improved from 0.98464 to 0.98631, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.1462 - accuracy: 0.9596 - val_loss: 0.0475 - val_accuracy: 0.9863\n",
      "Epoch 6/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.1425 - accuracy: 0.9611\n",
      "Epoch 00006: val_accuracy improved from 0.98631 to 0.98726, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.1424 - accuracy: 0.9611 - val_loss: 0.0438 - val_accuracy: 0.9873\n",
      "Epoch 7/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.1328 - accuracy: 0.9636\n",
      "Epoch 00007: val_accuracy did not improve from 0.98726\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.1328 - accuracy: 0.9636 - val_loss: 0.0451 - val_accuracy: 0.9862\n",
      "Epoch 8/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.1272 - accuracy: 0.9650\n",
      "Epoch 00008: val_accuracy did not improve from 0.98726\n",
      "2100/2100 [==============================] - 26s 13ms/step - loss: 0.1271 - accuracy: 0.9650 - val_loss: 0.0453 - val_accuracy: 0.9867\n",
      "Epoch 9/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.1102 - accuracy: 0.9691\n",
      "Epoch 00009: val_accuracy did not improve from 0.98726\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.1101 - accuracy: 0.9691 - val_loss: 0.0534 - val_accuracy: 0.9852\n",
      "Epoch 10/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.1036 - accuracy: 0.9705\n",
      "Epoch 00010: val_accuracy did not improve from 0.98726\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.1034 - accuracy: 0.9706 - val_loss: 0.0455 - val_accuracy: 0.9865\n",
      "Epoch 11/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.1041 - accuracy: 0.9723\n",
      "Epoch 00011: val_accuracy improved from 0.98726 to 0.98940, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 26s 13ms/step - loss: 0.1042 - accuracy: 0.9723 - val_loss: 0.0416 - val_accuracy: 0.9894\n",
      "Epoch 12/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0948 - accuracy: 0.9743\n",
      "Epoch 00012: val_accuracy improved from 0.98940 to 0.99083, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0948 - accuracy: 0.9743 - val_loss: 0.0365 - val_accuracy: 0.9908\n",
      "Epoch 13/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0921 - accuracy: 0.9752\n",
      "Epoch 00013: val_accuracy did not improve from 0.99083\n",
      "2100/2100 [==============================] - 28s 13ms/step - loss: 0.0921 - accuracy: 0.9751 - val_loss: 0.0370 - val_accuracy: 0.9900\n",
      "Epoch 14/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0889 - accuracy: 0.9762\n",
      "Epoch 00014: val_accuracy improved from 0.99083 to 0.99095, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 31s 15ms/step - loss: 0.0889 - accuracy: 0.9762 - val_loss: 0.0315 - val_accuracy: 0.9910\n",
      "Epoch 15/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9771\n",
      "Epoch 00015: val_accuracy did not improve from 0.99095\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0828 - accuracy: 0.9771 - val_loss: 0.0350 - val_accuracy: 0.9904\n",
      "Epoch 16/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9779\n",
      "Epoch 00016: val_accuracy did not improve from 0.99095\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0770 - accuracy: 0.9779 - val_loss: 0.0374 - val_accuracy: 0.9888\n",
      "Epoch 17/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0814 - accuracy: 0.9771\n",
      "Epoch 00017: val_accuracy did not improve from 0.99095\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0813 - accuracy: 0.9771 - val_loss: 0.0365 - val_accuracy: 0.9899\n",
      "Epoch 18/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0778 - accuracy: 0.9787\n",
      "Epoch 00018: val_accuracy improved from 0.99095 to 0.99143, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0777 - accuracy: 0.9787 - val_loss: 0.0339 - val_accuracy: 0.9914\n",
      "Epoch 19/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0717 - accuracy: 0.9800\n",
      "Epoch 00019: val_accuracy did not improve from 0.99143\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0717 - accuracy: 0.9800 - val_loss: 0.0396 - val_accuracy: 0.9901\n",
      "Epoch 20/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0736 - accuracy: 0.9799\n",
      "Epoch 00020: val_accuracy did not improve from 0.99143\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0736 - accuracy: 0.9799 - val_loss: 0.0314 - val_accuracy: 0.9914\n",
      "Epoch 21/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0689 - accuracy: 0.9813\n",
      "Epoch 00021: val_accuracy did not improve from 0.99143\n",
      "2100/2100 [==============================] - 26s 13ms/step - loss: 0.0689 - accuracy: 0.9813 - val_loss: 0.0369 - val_accuracy: 0.9905\n",
      "Epoch 22/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0686 - accuracy: 0.9813\n",
      "Epoch 00022: val_accuracy did not improve from 0.99143\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0685 - accuracy: 0.9813 - val_loss: 0.0394 - val_accuracy: 0.9898\n",
      "Epoch 23/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0676 - accuracy: 0.9816\n",
      "Epoch 00023: val_accuracy did not improve from 0.99143\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0675 - accuracy: 0.9816 - val_loss: 0.0355 - val_accuracy: 0.9899\n",
      "Epoch 24/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0641 - accuracy: 0.9818\n",
      "Epoch 00024: val_accuracy did not improve from 0.99143\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0641 - accuracy: 0.9818 - val_loss: 0.0379 - val_accuracy: 0.9890\n",
      "Epoch 25/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9832\n",
      "Epoch 00025: val_accuracy improved from 0.99143 to 0.99167, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0617 - accuracy: 0.9832 - val_loss: 0.0353 - val_accuracy: 0.9917\n",
      "Epoch 26/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9835\n",
      "Epoch 00026: val_accuracy did not improve from 0.99167\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0591 - accuracy: 0.9835 - val_loss: 0.0363 - val_accuracy: 0.9910\n",
      "Epoch 27/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0609 - accuracy: 0.9825\n",
      "Epoch 00027: val_accuracy did not improve from 0.99167\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0609 - accuracy: 0.9825 - val_loss: 0.0340 - val_accuracy: 0.9917\n",
      "Epoch 28/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0583 - accuracy: 0.9828\n",
      "Epoch 00028: val_accuracy improved from 0.99167 to 0.99226, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0583 - accuracy: 0.9829 - val_loss: 0.0294 - val_accuracy: 0.9923\n",
      "Epoch 29/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0579 - accuracy: 0.9839\n",
      "Epoch 00029: val_accuracy improved from 0.99226 to 0.99298, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0579 - accuracy: 0.9839 - val_loss: 0.0304 - val_accuracy: 0.9930\n",
      "Epoch 30/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0562 - accuracy: 0.9849\n",
      "Epoch 00030: val_accuracy did not improve from 0.99298\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0566 - accuracy: 0.9848 - val_loss: 0.0375 - val_accuracy: 0.9913\n",
      "Epoch 31/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0580 - accuracy: 0.9839\n",
      "Epoch 00031: val_accuracy did not improve from 0.99298\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0579 - accuracy: 0.9839 - val_loss: 0.0381 - val_accuracy: 0.9900\n",
      "Epoch 32/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0542 - accuracy: 0.9844\n",
      "Epoch 00032: val_accuracy did not improve from 0.99298\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0545 - accuracy: 0.9843 - val_loss: 0.0351 - val_accuracy: 0.9905\n",
      "Epoch 33/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0522 - accuracy: 0.9862\n",
      "Epoch 00033: val_accuracy did not improve from 0.99298\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0522 - accuracy: 0.9862 - val_loss: 0.0380 - val_accuracy: 0.9914\n",
      "Epoch 34/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0516 - accuracy: 0.9858\n",
      "Epoch 00034: val_accuracy did not improve from 0.99298\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0516 - accuracy: 0.9858 - val_loss: 0.0385 - val_accuracy: 0.9913\n",
      "Epoch 35/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0492 - accuracy: 0.9864\n",
      "Epoch 00035: val_accuracy did not improve from 0.99298\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0492 - accuracy: 0.9864 - val_loss: 0.0340 - val_accuracy: 0.9911\n",
      "Epoch 36/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9856\n",
      "Epoch 00036: val_accuracy did not improve from 0.99298\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0487 - accuracy: 0.9856 - val_loss: 0.0347 - val_accuracy: 0.9918\n",
      "Epoch 37/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0489 - accuracy: 0.9859\n",
      "Epoch 00037: val_accuracy did not improve from 0.99298\n",
      "2100/2100 [==============================] - 26s 13ms/step - loss: 0.0488 - accuracy: 0.9859 - val_loss: 0.0356 - val_accuracy: 0.9918\n",
      "Epoch 38/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9865\n",
      "Epoch 00038: val_accuracy did not improve from 0.99298\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0468 - accuracy: 0.9865 - val_loss: 0.0357 - val_accuracy: 0.9920\n",
      "Epoch 39/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9863\n",
      "Epoch 00039: val_accuracy did not improve from 0.99298\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0480 - accuracy: 0.9863 - val_loss: 0.0370 - val_accuracy: 0.9910\n",
      "Epoch 40/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9865\n",
      "Epoch 00040: val_accuracy did not improve from 0.99298\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0474 - accuracy: 0.9865 - val_loss: 0.0324 - val_accuracy: 0.9924\n",
      "Epoch 41/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.9894\n",
      "Epoch 00041: val_accuracy did not improve from 0.99298\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0403 - accuracy: 0.9894 - val_loss: 0.0317 - val_accuracy: 0.9927\n",
      "Epoch 42/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0349 - accuracy: 0.9897\n",
      "Epoch 00042: val_accuracy did not improve from 0.99298\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0349 - accuracy: 0.9898 - val_loss: 0.0358 - val_accuracy: 0.9925\n",
      "Epoch 43/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.9907\n",
      "Epoch 00043: val_accuracy did not improve from 0.99298\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0341 - accuracy: 0.9907 - val_loss: 0.0355 - val_accuracy: 0.9915\n",
      "Epoch 44/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9909\n",
      "Epoch 00044: val_accuracy did not improve from 0.99298\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0313 - accuracy: 0.9909 - val_loss: 0.0365 - val_accuracy: 0.9920\n",
      "Epoch 45/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0326 - accuracy: 0.9904\n",
      "Epoch 00045: val_accuracy did not improve from 0.99298\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0326 - accuracy: 0.9904 - val_loss: 0.0359 - val_accuracy: 0.9927\n",
      "Epoch 46/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0331 - accuracy: 0.9907\n",
      "Epoch 00046: val_accuracy did not improve from 0.99298\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0331 - accuracy: 0.9907 - val_loss: 0.0321 - val_accuracy: 0.9930\n",
      "Epoch 47/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.9906\n",
      "Epoch 00047: val_accuracy did not improve from 0.99298\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0333 - accuracy: 0.9906 - val_loss: 0.0324 - val_accuracy: 0.9927\n",
      "Epoch 48/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.9916\n",
      "Epoch 00048: val_accuracy improved from 0.99298 to 0.99333, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0298 - accuracy: 0.9916 - val_loss: 0.0313 - val_accuracy: 0.9933\n",
      "Epoch 49/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0354 - accuracy: 0.9910\n",
      "Epoch 00049: val_accuracy did not improve from 0.99333\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0354 - accuracy: 0.9910 - val_loss: 0.0379 - val_accuracy: 0.9914\n",
      "Epoch 50/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 0.9915\n",
      "Epoch 00050: val_accuracy did not improve from 0.99333\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0312 - accuracy: 0.9915 - val_loss: 0.0359 - val_accuracy: 0.9927\n",
      "Epoch 51/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.9916\n",
      "Epoch 00051: val_accuracy did not improve from 0.99333\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0298 - accuracy: 0.9916 - val_loss: 0.0345 - val_accuracy: 0.9930\n",
      "Epoch 52/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9917\n",
      "Epoch 00052: val_accuracy did not improve from 0.99333\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0305 - accuracy: 0.9917 - val_loss: 0.0353 - val_accuracy: 0.9931\n",
      "Epoch 53/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9914\n",
      "Epoch 00053: val_accuracy did not improve from 0.99333\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0303 - accuracy: 0.9913 - val_loss: 0.0377 - val_accuracy: 0.9915\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9925\n",
      "Epoch 00054: val_accuracy improved from 0.99333 to 0.99357, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0256 - accuracy: 0.9925 - val_loss: 0.0332 - val_accuracy: 0.9936\n",
      "Epoch 55/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9918\n",
      "Epoch 00055: val_accuracy did not improve from 0.99357\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0287 - accuracy: 0.9918 - val_loss: 0.0351 - val_accuracy: 0.9931\n",
      "Epoch 56/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9932\n",
      "Epoch 00056: val_accuracy did not improve from 0.99357\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0250 - accuracy: 0.9932 - val_loss: 0.0351 - val_accuracy: 0.9925\n",
      "Epoch 57/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0253 - accuracy: 0.9930\n",
      "Epoch 00057: val_accuracy improved from 0.99357 to 0.99369, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0253 - accuracy: 0.9931 - val_loss: 0.0322 - val_accuracy: 0.9937\n",
      "Epoch 58/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9931\n",
      "Epoch 00058: val_accuracy did not improve from 0.99369\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0256 - accuracy: 0.9931 - val_loss: 0.0345 - val_accuracy: 0.9937\n",
      "Epoch 59/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9931\n",
      "Epoch 00059: val_accuracy did not improve from 0.99369\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.0326 - val_accuracy: 0.9927\n",
      "Epoch 60/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0230 - accuracy: 0.9934\n",
      "Epoch 00060: val_accuracy did not improve from 0.99369\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0230 - accuracy: 0.9934 - val_loss: 0.0334 - val_accuracy: 0.9930\n",
      "Epoch 61/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9932 ETA: \n",
      "Epoch 00061: val_accuracy did not improve from 0.99369\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.0326 - val_accuracy: 0.9937\n",
      "Epoch 62/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9939\n",
      "Epoch 00062: val_accuracy did not improve from 0.99369\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0216 - accuracy: 0.9939 - val_loss: 0.0330 - val_accuracy: 0.9932\n",
      "Epoch 63/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.9937\n",
      "Epoch 00063: val_accuracy did not improve from 0.99369\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0224 - accuracy: 0.9937 - val_loss: 0.0332 - val_accuracy: 0.9931\n",
      "Epoch 64/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9939\n",
      "Epoch 00064: val_accuracy did not improve from 0.99369\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0214 - accuracy: 0.9939 - val_loss: 0.0309 - val_accuracy: 0.9933\n",
      "Epoch 65/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9939\n",
      "Epoch 00065: val_accuracy did not improve from 0.99369\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0219 - accuracy: 0.9940 - val_loss: 0.0333 - val_accuracy: 0.9935\n",
      "Epoch 66/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9938\n",
      "Epoch 00066: val_accuracy did not improve from 0.99369\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0228 - accuracy: 0.9938 - val_loss: 0.0341 - val_accuracy: 0.9930\n",
      "Epoch 67/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9931\n",
      "Epoch 00067: val_accuracy did not improve from 0.99369\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0241 - accuracy: 0.9932 - val_loss: 0.0319 - val_accuracy: 0.9937\n",
      "Epoch 68/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9942\n",
      "Epoch 00068: val_accuracy did not improve from 0.99369\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.0342 - val_accuracy: 0.9929\n",
      "Epoch 69/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9941\n",
      "Epoch 00069: val_accuracy did not improve from 0.99369\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0210 - accuracy: 0.9941 - val_loss: 0.0342 - val_accuracy: 0.9923\n",
      "Epoch 70/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9945\n",
      "Epoch 00070: val_accuracy did not improve from 0.99369\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0198 - accuracy: 0.9945 - val_loss: 0.0338 - val_accuracy: 0.9931\n",
      "Epoch 71/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9942\n",
      "Epoch 00071: val_accuracy did not improve from 0.99369\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 0.0327 - val_accuracy: 0.9932\n",
      "Epoch 72/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.9943\n",
      "Epoch 00072: val_accuracy did not improve from 0.99369\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.0333 - val_accuracy: 0.9936\n",
      "Epoch 73/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9945\n",
      "Epoch 00073: val_accuracy did not improve from 0.99369\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 0.0311 - val_accuracy: 0.9936\n",
      "Epoch 74/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9949 ETA: 0s - loss: 0.0196 - accu\n",
      "Epoch 00074: val_accuracy did not improve from 0.99369\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0197 - accuracy: 0.9949 - val_loss: 0.0321 - val_accuracy: 0.9937\n",
      "Epoch 75/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9952\n",
      "Epoch 00075: val_accuracy improved from 0.99369 to 0.99381, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0179 - accuracy: 0.9952 - val_loss: 0.0327 - val_accuracy: 0.9938\n",
      "Epoch 76/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9944\n",
      "Epoch 00076: val_accuracy did not improve from 0.99381\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0206 - accuracy: 0.9943 - val_loss: 0.0321 - val_accuracy: 0.9935\n",
      "Epoch 77/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9950\n",
      "Epoch 00077: val_accuracy did not improve from 0.99381\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0175 - accuracy: 0.9950 - val_loss: 0.0330 - val_accuracy: 0.9935\n",
      "Epoch 78/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.9946\n",
      "Epoch 00078: val_accuracy did not improve from 0.99381\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0188 - accuracy: 0.9946 - val_loss: 0.0320 - val_accuracy: 0.9938\n",
      "Epoch 79/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9948\n",
      "Epoch 00079: val_accuracy improved from 0.99381 to 0.99405, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0192 - accuracy: 0.9948 - val_loss: 0.0323 - val_accuracy: 0.9940\n",
      "Epoch 80/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9947\n",
      "Epoch 00080: val_accuracy did not improve from 0.99405\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.0312 - val_accuracy: 0.9938\n",
      "Epoch 81/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9943 ETA: 2s -\n",
      "Epoch 00081: val_accuracy did not improve from 0.99405\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.0325 - val_accuracy: 0.9940\n",
      "Epoch 82/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.9954\n",
      "Epoch 00082: val_accuracy did not improve from 0.99405\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0173 - accuracy: 0.9954 - val_loss: 0.0325 - val_accuracy: 0.9938\n",
      "Epoch 83/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9953\n",
      "Epoch 00083: val_accuracy improved from 0.99405 to 0.99417, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0172 - accuracy: 0.9953 - val_loss: 0.0319 - val_accuracy: 0.9942\n",
      "Epoch 84/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9953\n",
      "Epoch 00084: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.0315 - val_accuracy: 0.9942\n",
      "Epoch 85/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9947\n",
      "Epoch 00085: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.0330 - val_accuracy: 0.9937\n",
      "Epoch 86/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9955\n",
      "Epoch 00086: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.0319 - val_accuracy: 0.9942\n",
      "Epoch 87/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9957\n",
      "Epoch 00087: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.0334 - val_accuracy: 0.9940\n",
      "Epoch 88/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9952\n",
      "Epoch 00088: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.0326 - val_accuracy: 0.9938\n",
      "Epoch 89/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9961\n",
      "Epoch 00089: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 0.0333 - val_accuracy: 0.9938\n",
      "Epoch 90/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9959\n",
      "Epoch 00090: val_accuracy improved from 0.99417 to 0.99452, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0160 - accuracy: 0.9959 - val_loss: 0.0324 - val_accuracy: 0.9945\n",
      "Epoch 91/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9957\n",
      "Epoch 00091: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0165 - accuracy: 0.9957 - val_loss: 0.0320 - val_accuracy: 0.9945\n",
      "Epoch 92/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9955 ETA: 0s - loss: 0.0164 - accuracy: 0.\n",
      "Epoch 00092: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0164 - accuracy: 0.9955 - val_loss: 0.0326 - val_accuracy: 0.9942\n",
      "Epoch 93/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9956\n",
      "Epoch 00093: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0160 - accuracy: 0.9956 - val_loss: 0.0325 - val_accuracy: 0.9943\n",
      "Epoch 94/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9955\n",
      "Epoch 00094: val_accuracy did not improve from 0.99452\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.0334 - val_accuracy: 0.9940\n",
      "Epoch 95/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9954\n",
      "Epoch 00095: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.0333 - val_accuracy: 0.9942\n",
      "Epoch 96/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9953\n",
      "Epoch 00096: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 0.0334 - val_accuracy: 0.9943\n",
      "Epoch 97/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9955\n",
      "Epoch 00097: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0156 - accuracy: 0.9955 - val_loss: 0.0326 - val_accuracy: 0.9943\n",
      "Epoch 98/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9949\n",
      "Epoch 00098: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0327 - val_accuracy: 0.9944\n",
      "Epoch 99/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9954\n",
      "Epoch 00099: val_accuracy did not improve from 0.99452\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.0331 - val_accuracy: 0.9940\n",
      "Epoch 100/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9955\n",
      "Epoch 00100: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0161 - accuracy: 0.9955 - val_loss: 0.0326 - val_accuracy: 0.9942\n",
      "Epoch 101/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9956\n",
      "Epoch 00101: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.0322 - val_accuracy: 0.9940\n",
      "Epoch 102/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.99 - ETA: 0s - loss: 0.0155 - accuracy: 0.9958\n",
      "Epoch 00102: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.0332 - val_accuracy: 0.9943\n",
      "Epoch 103/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9959\n",
      "Epoch 00103: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0162 - accuracy: 0.9959 - val_loss: 0.0329 - val_accuracy: 0.9944\n",
      "Epoch 104/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9952\n",
      "Epoch 00104: val_accuracy did not improve from 0.99452\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.0326 - val_accuracy: 0.9943\n",
      "Epoch 105/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9956\n",
      "Epoch 00105: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.0325 - val_accuracy: 0.9944\n",
      "Epoch 106/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9957\n",
      "Epoch 00106: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0165 - accuracy: 0.9957 - val_loss: 0.0325 - val_accuracy: 0.9942\n",
      "Epoch 107/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9956\n",
      "Epoch 00107: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0160 - accuracy: 0.9956 - val_loss: 0.0321 - val_accuracy: 0.9939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9955\n",
      "Epoch 00108: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.0326 - val_accuracy: 0.9943\n",
      "Epoch 109/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9960\n",
      "Epoch 00109: val_accuracy did not improve from 0.99452\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0161 - accuracy: 0.9960 - val_loss: 0.0329 - val_accuracy: 0.9942\n",
      "Epoch 110/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9960\n",
      "Epoch 00110: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0325 - val_accuracy: 0.9942\n",
      "Epoch 111/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9958\n",
      "Epoch 00111: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.0334 - val_accuracy: 0.9942\n",
      "Epoch 112/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9956\n",
      "Epoch 00112: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.0327 - val_accuracy: 0.9940\n",
      "Epoch 113/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9954\n",
      "Epoch 00113: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.0327 - val_accuracy: 0.9943\n",
      "Epoch 114/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9961\n",
      "Epoch 00114: val_accuracy did not improve from 0.99452\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 0.0329 - val_accuracy: 0.9943\n",
      "Epoch 115/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9955\n",
      "Epoch 00115: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0146 - accuracy: 0.9955 - val_loss: 0.0330 - val_accuracy: 0.9942\n",
      "Epoch 116/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9959\n",
      "Epoch 00116: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0152 - accuracy: 0.9959 - val_loss: 0.0335 - val_accuracy: 0.9942\n",
      "Epoch 117/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9955\n",
      "Epoch 00117: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0157 - accuracy: 0.9955 - val_loss: 0.0329 - val_accuracy: 0.9940\n",
      "Epoch 118/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9953\n",
      "Epoch 00118: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.0330 - val_accuracy: 0.9944\n",
      "Epoch 119/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9960\n",
      "Epoch 00119: val_accuracy did not improve from 0.99452\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0323 - val_accuracy: 0.9943\n",
      "Epoch 120/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9958\n",
      "Epoch 00120: val_accuracy did not improve from 0.99452\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.0331 - val_accuracy: 0.9940\n",
      "Epoch 00120: early stopping\n",
      "Epoch 1/200\n",
      "   2/2100 [..............................] - ETA: 47:55 - loss: 2.7411 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0145s vs `on_train_batch_end` time: 2.7090s). Check your callbacks.\n",
      "2094/2100 [============================>.] - ETA: 0s - loss: 0.4855 - accuracy: 0.8552\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96190, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 28s 13ms/step - loss: 0.4848 - accuracy: 0.8553 - val_loss: 0.1217 - val_accuracy: 0.9619\n",
      "Epoch 2/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.2422 - accuracy: 0.9319\n",
      "Epoch 00002: val_accuracy improved from 0.96190 to 0.97345, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.2422 - accuracy: 0.9319 - val_loss: 0.0881 - val_accuracy: 0.9735\n",
      "Epoch 3/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.1950 - accuracy: 0.9475\n",
      "Epoch 00003: val_accuracy improved from 0.97345 to 0.98048, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1951 - accuracy: 0.9474 - val_loss: 0.0667 - val_accuracy: 0.9805\n",
      "Epoch 4/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.1699 - accuracy: 0.9539\n",
      "Epoch 00004: val_accuracy improved from 0.98048 to 0.98262, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1699 - accuracy: 0.9539 - val_loss: 0.0541 - val_accuracy: 0.9826\n",
      "Epoch 5/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.1627 - accuracy: 0.9555 ETA: 0s - loss: 0.1630 - accuracy: 0.95\n",
      "Epoch 00005: val_accuracy improved from 0.98262 to 0.98429, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1627 - accuracy: 0.9555 - val_loss: 0.0523 - val_accuracy: 0.9843\n",
      "Epoch 6/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.1410 - accuracy: 0.9617\n",
      "Epoch 00006: val_accuracy improved from 0.98429 to 0.98726, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1408 - accuracy: 0.9617 - val_loss: 0.0451 - val_accuracy: 0.9873\n",
      "Epoch 7/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.1290 - accuracy: 0.9646\n",
      "Epoch 00007: val_accuracy did not improve from 0.98726\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1289 - accuracy: 0.9646 - val_loss: 0.0454 - val_accuracy: 0.9862\n",
      "Epoch 8/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.1255 - accuracy: 0.9662\n",
      "Epoch 00008: val_accuracy improved from 0.98726 to 0.98810, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1256 - accuracy: 0.9662 - val_loss: 0.0454 - val_accuracy: 0.9881\n",
      "Epoch 9/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.1140 - accuracy: 0.9694\n",
      "Epoch 00009: val_accuracy improved from 0.98810 to 0.98893, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1138 - accuracy: 0.9695 - val_loss: 0.0421 - val_accuracy: 0.9889\n",
      "Epoch 10/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.1089 - accuracy: 0.9703\n",
      "Epoch 00010: val_accuracy did not improve from 0.98893\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1089 - accuracy: 0.9703 - val_loss: 0.0448 - val_accuracy: 0.9862\n",
      "Epoch 11/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.1031 - accuracy: 0.9710\n",
      "Epoch 00011: val_accuracy did not improve from 0.98893\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1031 - accuracy: 0.9710 - val_loss: 0.0428 - val_accuracy: 0.9882\n",
      "Epoch 12/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.1002 - accuracy: 0.9725\n",
      "Epoch 00012: val_accuracy did not improve from 0.98893\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.1003 - accuracy: 0.9725 - val_loss: 0.0402 - val_accuracy: 0.9885\n",
      "Epoch 13/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0959 - accuracy: 0.9741\n",
      "Epoch 00013: val_accuracy improved from 0.98893 to 0.98917, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0959 - accuracy: 0.9741 - val_loss: 0.0369 - val_accuracy: 0.9892\n",
      "Epoch 14/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0912 - accuracy: 0.9751\n",
      "Epoch 00014: val_accuracy improved from 0.98917 to 0.99000, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0912 - accuracy: 0.9751 - val_loss: 0.0352 - val_accuracy: 0.9900\n",
      "Epoch 15/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.9754\n",
      "Epoch 00015: val_accuracy did not improve from 0.99000\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0853 - accuracy: 0.9754 - val_loss: 0.0384 - val_accuracy: 0.9893\n",
      "Epoch 16/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0791 - accuracy: 0.9778 ETA: 0s - loss:\n",
      "Epoch 00016: val_accuracy did not improve from 0.99000\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0791 - accuracy: 0.9778 - val_loss: 0.0416 - val_accuracy: 0.9889\n",
      "Epoch 17/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0781 - accuracy: 0.9789\n",
      "Epoch 00017: val_accuracy did not improve from 0.99000\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0786 - accuracy: 0.9788 - val_loss: 0.0389 - val_accuracy: 0.9893\n",
      "Epoch 18/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0797 - accuracy: 0.9778\n",
      "Epoch 00018: val_accuracy did not improve from 0.99000\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0797 - accuracy: 0.9778 - val_loss: 0.0466 - val_accuracy: 0.9887\n",
      "Epoch 19/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0746 - accuracy: 0.9796\n",
      "Epoch 00019: val_accuracy did not improve from 0.99000\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0746 - accuracy: 0.9796 - val_loss: 0.0398 - val_accuracy: 0.9900\n",
      "Epoch 20/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0739 - accuracy: 0.9793\n",
      "Epoch 00020: val_accuracy did not improve from 0.99000\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0740 - accuracy: 0.9793 - val_loss: 0.0377 - val_accuracy: 0.9889\n",
      "Epoch 21/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0758 - accuracy: 0.9798 ETA: 0s - loss: 0.0760 - accuracy: \n",
      "Epoch 00021: val_accuracy improved from 0.99000 to 0.99107, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0759 - accuracy: 0.9798 - val_loss: 0.0355 - val_accuracy: 0.9911\n",
      "Epoch 22/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0710 - accuracy: 0.9798\n",
      "Epoch 00022: val_accuracy improved from 0.99107 to 0.99190, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0712 - accuracy: 0.9798 - val_loss: 0.0313 - val_accuracy: 0.9919\n",
      "Epoch 23/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0747 - accuracy: 0.9803\n",
      "Epoch 00023: val_accuracy did not improve from 0.99190\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0746 - accuracy: 0.9803 - val_loss: 0.0376 - val_accuracy: 0.9889\n",
      "Epoch 24/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0633 - accuracy: 0.9823\n",
      "Epoch 00024: val_accuracy did not improve from 0.99190\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0633 - accuracy: 0.9823 - val_loss: 0.0331 - val_accuracy: 0.9914\n",
      "Epoch 25/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0664 - accuracy: 0.9810\n",
      "Epoch 00025: val_accuracy did not improve from 0.99190\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0664 - accuracy: 0.9810 - val_loss: 0.0336 - val_accuracy: 0.9915\n",
      "Epoch 26/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0613 - accuracy: 0.9822\n",
      "Epoch 00026: val_accuracy did not improve from 0.99190\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0613 - accuracy: 0.9822 - val_loss: 0.0329 - val_accuracy: 0.9912\n",
      "Epoch 27/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0642 - accuracy: 0.9819\n",
      "Epoch 00027: val_accuracy did not improve from 0.99190\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0644 - accuracy: 0.9819 - val_loss: 0.0376 - val_accuracy: 0.9918\n",
      "Epoch 28/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0611 - accuracy: 0.9832\n",
      "Epoch 00028: val_accuracy did not improve from 0.99190\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0611 - accuracy: 0.9832 - val_loss: 0.0352 - val_accuracy: 0.9913\n",
      "Epoch 29/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0590 - accuracy: 0.9834\n",
      "Epoch 00029: val_accuracy did not improve from 0.99190\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0589 - accuracy: 0.9835 - val_loss: 0.0381 - val_accuracy: 0.9911\n",
      "Epoch 30/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0581 - accuracy: 0.9835\n",
      "Epoch 00030: val_accuracy did not improve from 0.99190\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0581 - accuracy: 0.9835 - val_loss: 0.0389 - val_accuracy: 0.9910\n",
      "Epoch 31/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0609 - accuracy: 0.9839\n",
      "Epoch 00031: val_accuracy did not improve from 0.99190\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0609 - accuracy: 0.9839 - val_loss: 0.0405 - val_accuracy: 0.9910\n",
      "Epoch 32/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0533 - accuracy: 0.9852\n",
      "Epoch 00032: val_accuracy did not improve from 0.99190\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0533 - accuracy: 0.9852 - val_loss: 0.0391 - val_accuracy: 0.9917\n",
      "Epoch 33/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 0.9844 ETA: 0s - loss: 0.0560 - \n",
      "Epoch 00033: val_accuracy did not improve from 0.99190\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0564 - accuracy: 0.9844 - val_loss: 0.0395 - val_accuracy: 0.9913\n",
      "Epoch 34/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9849\n",
      "Epoch 00034: val_accuracy improved from 0.99190 to 0.99202, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0510 - accuracy: 0.9849 - val_loss: 0.0358 - val_accuracy: 0.9920\n",
      "Epoch 35/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0537 - accuracy: 0.9855\n",
      "Epoch 00035: val_accuracy did not improve from 0.99202\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0537 - accuracy: 0.9855 - val_loss: 0.0450 - val_accuracy: 0.9893\n",
      "Epoch 36/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0504 - accuracy: 0.9855\n",
      "Epoch 00036: val_accuracy improved from 0.99202 to 0.99238, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0504 - accuracy: 0.9854 - val_loss: 0.0382 - val_accuracy: 0.9924\n",
      "Epoch 37/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9833\n",
      "Epoch 00037: val_accuracy did not improve from 0.99238\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0555 - accuracy: 0.9833 - val_loss: 0.0356 - val_accuracy: 0.9918\n",
      "Epoch 38/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9851\n",
      "Epoch 00038: val_accuracy did not improve from 0.99238\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0527 - accuracy: 0.9851 - val_loss: 0.0383 - val_accuracy: 0.9918\n",
      "Epoch 39/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0497 - accuracy: 0.9851\n",
      "Epoch 00039: val_accuracy did not improve from 0.99238\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0498 - accuracy: 0.9851 - val_loss: 0.0376 - val_accuracy: 0.9908\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9865\n",
      "Epoch 00040: val_accuracy did not improve from 0.99238\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0501 - accuracy: 0.9865 - val_loss: 0.0378 - val_accuracy: 0.9918\n",
      "Epoch 41/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0453 - accuracy: 0.9871\n",
      "Epoch 00041: val_accuracy did not improve from 0.99238\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0453 - accuracy: 0.9871 - val_loss: 0.0373 - val_accuracy: 0.9918\n",
      "Epoch 42/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0482 - accuracy: 0.9864\n",
      "Epoch 00042: val_accuracy did not improve from 0.99238\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0483 - accuracy: 0.9864 - val_loss: 0.0392 - val_accuracy: 0.9917\n",
      "Epoch 43/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 0.9853\n",
      "Epoch 00043: val_accuracy did not improve from 0.99238\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0507 - accuracy: 0.9853 - val_loss: 0.0407 - val_accuracy: 0.9914\n",
      "Epoch 44/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0469 - accuracy: 0.9868\n",
      "Epoch 00044: val_accuracy did not improve from 0.99238\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0469 - accuracy: 0.9868 - val_loss: 0.0377 - val_accuracy: 0.9911\n",
      "Epoch 45/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.9872\n",
      "Epoch 00045: val_accuracy did not improve from 0.99238\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0445 - accuracy: 0.9872 - val_loss: 0.0439 - val_accuracy: 0.9910\n",
      "Epoch 46/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0442 - accuracy: 0.9869\n",
      "Epoch 00046: val_accuracy did not improve from 0.99238\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0441 - accuracy: 0.9870 - val_loss: 0.0431 - val_accuracy: 0.9901\n",
      "Epoch 47/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9884 ETA: 0s - loss: 0.0400 - accuracy: \n",
      "Epoch 00047: val_accuracy did not improve from 0.99238\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0399 - accuracy: 0.9884 - val_loss: 0.0402 - val_accuracy: 0.9907\n",
      "Epoch 48/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9910\n",
      "Epoch 00048: val_accuracy did not improve from 0.99238\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0308 - accuracy: 0.9910 - val_loss: 0.0352 - val_accuracy: 0.9923\n",
      "Epoch 49/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0327 - accuracy: 0.9902\n",
      "Epoch 00049: val_accuracy did not improve from 0.99238\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0327 - accuracy: 0.9902 - val_loss: 0.0351 - val_accuracy: 0.9923\n",
      "Epoch 50/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0360 - accuracy: 0.9901\n",
      "Epoch 00050: val_accuracy did not improve from 0.99238\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0359 - accuracy: 0.9901 - val_loss: 0.0396 - val_accuracy: 0.9918\n",
      "Epoch 51/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0326 - accuracy: 0.9909\n",
      "Epoch 00051: val_accuracy did not improve from 0.99238\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0326 - accuracy: 0.9909 - val_loss: 0.0399 - val_accuracy: 0.9920\n",
      "Epoch 52/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9910\n",
      "Epoch 00052: val_accuracy did not improve from 0.99238\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0321 - accuracy: 0.9910 - val_loss: 0.0401 - val_accuracy: 0.9917\n",
      "Epoch 53/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 0.9915 ETA - ETA: \n",
      "Epoch 00053: val_accuracy did not improve from 0.99238\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0313 - accuracy: 0.9915 - val_loss: 0.0404 - val_accuracy: 0.9915\n",
      "Epoch 54/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9925\n",
      "Epoch 00054: val_accuracy improved from 0.99238 to 0.99250, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0275 - accuracy: 0.9925 - val_loss: 0.0415 - val_accuracy: 0.9925\n",
      "Epoch 55/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9915\n",
      "Epoch 00055: val_accuracy improved from 0.99250 to 0.99274, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0304 - accuracy: 0.9915 - val_loss: 0.0367 - val_accuracy: 0.9927\n",
      "Epoch 56/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9909\n",
      "Epoch 00056: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0338 - accuracy: 0.9910 - val_loss: 0.0388 - val_accuracy: 0.9919\n",
      "Epoch 57/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9916\n",
      "Epoch 00057: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0289 - accuracy: 0.9916 - val_loss: 0.0413 - val_accuracy: 0.9918\n",
      "Epoch 58/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.9917\n",
      "Epoch 00058: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0295 - accuracy: 0.9917 - val_loss: 0.0435 - val_accuracy: 0.9920\n",
      "Epoch 59/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9912\n",
      "Epoch 00059: val_accuracy did not improve from 0.99274\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 0.0437 - val_accuracy: 0.9919\n",
      "Epoch 60/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9927 ETA: 0s - loss: 0.0261 - ac\n",
      "Epoch 00060: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0259 - accuracy: 0.9927 - val_loss: 0.0418 - val_accuracy: 0.9923\n",
      "Epoch 61/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9933\n",
      "Epoch 00061: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0225 - accuracy: 0.9932 - val_loss: 0.0417 - val_accuracy: 0.9923\n",
      "Epoch 62/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0253 - accuracy: 0.9928\n",
      "Epoch 00062: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0253 - accuracy: 0.9928 - val_loss: 0.0426 - val_accuracy: 0.9919\n",
      "Epoch 63/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9928\n",
      "Epoch 00063: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0253 - accuracy: 0.9928 - val_loss: 0.0411 - val_accuracy: 0.9923\n",
      "Epoch 64/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0250 - accuracy: 0.9933\n",
      "Epoch 00064: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0250 - accuracy: 0.9933 - val_loss: 0.0430 - val_accuracy: 0.9918\n",
      "Epoch 65/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9934\n",
      "Epoch 00065: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0215 - accuracy: 0.9934 - val_loss: 0.0450 - val_accuracy: 0.9921\n",
      "Epoch 66/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9931\n",
      "Epoch 00066: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0241 - accuracy: 0.9931 - val_loss: 0.0448 - val_accuracy: 0.9913\n",
      "Epoch 67/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9932\n",
      "Epoch 00067: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0233 - accuracy: 0.9932 - val_loss: 0.0455 - val_accuracy: 0.9914\n",
      "Epoch 68/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9939\n",
      "Epoch 00068: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0233 - accuracy: 0.9939 - val_loss: 0.0410 - val_accuracy: 0.9924\n",
      "Epoch 69/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.9928\n",
      "Epoch 00069: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0246 - accuracy: 0.9928 - val_loss: 0.0416 - val_accuracy: 0.9921\n",
      "Epoch 70/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9942\n",
      "Epoch 00070: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.0439 - val_accuracy: 0.9918\n",
      "Epoch 71/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.9932\n",
      "Epoch 00071: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0246 - accuracy: 0.9932 - val_loss: 0.0418 - val_accuracy: 0.9920\n",
      "Epoch 72/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0226 - accuracy: 0.9933\n",
      "Epoch 00072: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0438 - val_accuracy: 0.9923\n",
      "Epoch 73/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9941\n",
      "Epoch 00073: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0208 - accuracy: 0.9940 - val_loss: 0.0420 - val_accuracy: 0.9920\n",
      "Epoch 74/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0228 - accuracy: 0.9936\n",
      "Epoch 00074: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0228 - accuracy: 0.9936 - val_loss: 0.0411 - val_accuracy: 0.9919\n",
      "Epoch 75/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9933\n",
      "Epoch 00075: val_accuracy did not improve from 0.99274\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.0417 - val_accuracy: 0.9925\n",
      "Epoch 76/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9941\n",
      "Epoch 00076: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0204 - accuracy: 0.9941 - val_loss: 0.0409 - val_accuracy: 0.9925\n",
      "Epoch 77/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.9947\n",
      "Epoch 00077: val_accuracy did not improve from 0.99274\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.0400 - val_accuracy: 0.9927\n",
      "Epoch 78/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9941 E\n",
      "Epoch 00078: val_accuracy improved from 0.99274 to 0.99286, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0207 - accuracy: 0.9941 - val_loss: 0.0419 - val_accuracy: 0.9929\n",
      "Epoch 79/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9947\n",
      "Epoch 00079: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0201 - accuracy: 0.9947 - val_loss: 0.0408 - val_accuracy: 0.9925\n",
      "Epoch 80/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9944\n",
      "Epoch 00080: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.0404 - val_accuracy: 0.9921\n",
      "Epoch 81/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9946\n",
      "Epoch 00081: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0190 - accuracy: 0.9946 - val_loss: 0.0416 - val_accuracy: 0.9926\n",
      "Epoch 82/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9944\n",
      "Epoch 00082: val_accuracy did not improve from 0.99286\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.0417 - val_accuracy: 0.9924\n",
      "Epoch 83/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9950\n",
      "Epoch 00083: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0179 - accuracy: 0.9950 - val_loss: 0.0420 - val_accuracy: 0.9923\n",
      "Epoch 84/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9943\n",
      "Epoch 00084: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.0428 - val_accuracy: 0.9923\n",
      "Epoch 85/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9947\n",
      "Epoch 00085: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.0424 - val_accuracy: 0.9919\n",
      "Epoch 86/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9953\n",
      "Epoch 00086: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 0.0421 - val_accuracy: 0.9923\n",
      "Epoch 87/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9948\n",
      "Epoch 00087: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0192 - accuracy: 0.9948 - val_loss: 0.0423 - val_accuracy: 0.9921\n",
      "Epoch 88/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9954\n",
      "Epoch 00088: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.0413 - val_accuracy: 0.9921\n",
      "Epoch 89/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9949\n",
      "Epoch 00089: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0179 - accuracy: 0.9949 - val_loss: 0.0417 - val_accuracy: 0.9923\n",
      "Epoch 90/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9948\n",
      "Epoch 00090: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.0412 - val_accuracy: 0.9921\n",
      "Epoch 91/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9948\n",
      "Epoch 00091: val_accuracy did not improve from 0.99286\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.0417 - val_accuracy: 0.9929\n",
      "Epoch 92/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9947\n",
      "Epoch 00092: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.0424 - val_accuracy: 0.9929\n",
      "Epoch 93/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9949\n",
      "Epoch 00093: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0184 - accuracy: 0.9949 - val_loss: 0.0426 - val_accuracy: 0.9925\n",
      "Epoch 94/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9956\n",
      "Epoch 00094: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0165 - accuracy: 0.9956 - val_loss: 0.0430 - val_accuracy: 0.9924\n",
      "Epoch 95/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9958\n",
      "Epoch 00095: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.0426 - val_accuracy: 0.9925\n",
      "Epoch 96/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9958\n",
      "Epoch 00096: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.0421 - val_accuracy: 0.9927\n",
      "Epoch 97/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9953\n",
      "Epoch 00097: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.0428 - val_accuracy: 0.9924\n",
      "Epoch 98/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9954\n",
      "Epoch 00098: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.0426 - val_accuracy: 0.9926\n",
      "Epoch 99/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9958\n",
      "Epoch 00099: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.0426 - val_accuracy: 0.9926\n",
      "Epoch 100/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9953\n",
      "Epoch 00100: val_accuracy did not improve from 0.99286\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.0423 - val_accuracy: 0.9925\n",
      "Epoch 101/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9959\n",
      "Epoch 00101: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0164 - accuracy: 0.9959 - val_loss: 0.0428 - val_accuracy: 0.9927\n",
      "Epoch 102/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9950\n",
      "Epoch 00102: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.0423 - val_accuracy: 0.9924\n",
      "Epoch 103/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9951\n",
      "Epoch 00103: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.0423 - val_accuracy: 0.9925\n",
      "Epoch 104/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9956 E\n",
      "Epoch 00104: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.0414 - val_accuracy: 0.9927\n",
      "Epoch 105/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9950\n",
      "Epoch 00105: val_accuracy did not improve from 0.99286\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0175 - accuracy: 0.9950 - val_loss: 0.0423 - val_accuracy: 0.9924\n",
      "Epoch 106/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9950\n",
      "Epoch 00106: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 0.0421 - val_accuracy: 0.9925\n",
      "Epoch 107/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9954\n",
      "Epoch 00107: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.0425 - val_accuracy: 0.9925\n",
      "Epoch 108/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9959\n",
      "Epoch 00108: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0150 - accuracy: 0.9960 - val_loss: 0.0421 - val_accuracy: 0.9925\n",
      "Epoch 00108: early stopping\n",
      "Epoch 1/200\n",
      "   2/2100 [..............................] - ETA: 48:47 - loss: 3.1842 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0265s vs `on_train_batch_end` time: 2.7496s). Check your callbacks.\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.4834 - accuracy: 0.8561WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0160s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96762, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 29s 14ms/step - loss: 0.4831 - accuracy: 0.8561 - val_loss: 0.0991 - val_accuracy: 0.9676\n",
      "Epoch 2/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.2464 - accuracy: 0.9311\n",
      "Epoch 00002: val_accuracy improved from 0.96762 to 0.97762, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.2463 - accuracy: 0.9312 - val_loss: 0.0767 - val_accuracy: 0.9776\n",
      "Epoch 3/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.1972 - accuracy: 0.9460\n",
      "Epoch 00003: val_accuracy improved from 0.97762 to 0.97810, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1971 - accuracy: 0.9460 - val_loss: 0.0669 - val_accuracy: 0.9781\n",
      "Epoch 4/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.1787 - accuracy: 0.9515\n",
      "Epoch 00004: val_accuracy improved from 0.97810 to 0.98345, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1786 - accuracy: 0.9515 - val_loss: 0.0526 - val_accuracy: 0.9835\n",
      "Epoch 5/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.1594 - accuracy: 0.9544\n",
      "Epoch 00005: val_accuracy did not improve from 0.98345\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1593 - accuracy: 0.9545 - val_loss: 0.0502 - val_accuracy: 0.9835\n",
      "Epoch 6/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.1440 - accuracy: 0.9588\n",
      "Epoch 00006: val_accuracy improved from 0.98345 to 0.98583, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1442 - accuracy: 0.9588 - val_loss: 0.0455 - val_accuracy: 0.9858\n",
      "Epoch 7/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.1276 - accuracy: 0.9649\n",
      "Epoch 00007: val_accuracy improved from 0.98583 to 0.98714, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1275 - accuracy: 0.9649 - val_loss: 0.0437 - val_accuracy: 0.9871\n",
      "Epoch 8/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.1254 - accuracy: 0.9645\n",
      "Epoch 00008: val_accuracy improved from 0.98714 to 0.98798, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1259 - accuracy: 0.9644 - val_loss: 0.0430 - val_accuracy: 0.9880\n",
      "Epoch 9/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.1167 - accuracy: 0.9679\n",
      "Epoch 00009: val_accuracy improved from 0.98798 to 0.98881, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1165 - accuracy: 0.9679 - val_loss: 0.0366 - val_accuracy: 0.9888\n",
      "Epoch 10/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.1109 - accuracy: 0.9690\n",
      "Epoch 00010: val_accuracy did not improve from 0.98881\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1109 - accuracy: 0.9690 - val_loss: 0.0381 - val_accuracy: 0.9883\n",
      "Epoch 11/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.1126 - accuracy: 0.9690\n",
      "Epoch 00011: val_accuracy improved from 0.98881 to 0.98917, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.1126 - accuracy: 0.9690 - val_loss: 0.0360 - val_accuracy: 0.9892\n",
      "Epoch 12/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.1071 - accuracy: 0.9706\n",
      "Epoch 00012: val_accuracy improved from 0.98917 to 0.98964, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1073 - accuracy: 0.9706 - val_loss: 0.0316 - val_accuracy: 0.9896\n",
      "Epoch 13/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0984 - accuracy: 0.9726\n",
      "Epoch 00013: val_accuracy did not improve from 0.98964\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0983 - accuracy: 0.9726 - val_loss: 0.0402 - val_accuracy: 0.9879\n",
      "Epoch 14/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9743\n",
      "Epoch 00014: val_accuracy did not improve from 0.98964\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0955 - accuracy: 0.9743 - val_loss: 0.0339 - val_accuracy: 0.9896\n",
      "Epoch 15/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0925 - accuracy: 0.9755\n",
      "Epoch 00015: val_accuracy improved from 0.98964 to 0.99000, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0924 - accuracy: 0.9755 - val_loss: 0.0351 - val_accuracy: 0.9900\n",
      "Epoch 16/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0897 - accuracy: 0.9747\n",
      "Epoch 00016: val_accuracy improved from 0.99000 to 0.99048, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0897 - accuracy: 0.9747 - val_loss: 0.0332 - val_accuracy: 0.9905\n",
      "Epoch 17/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0857 - accuracy: 0.9763\n",
      "Epoch 00017: val_accuracy did not improve from 0.99048\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0856 - accuracy: 0.9762 - val_loss: 0.0365 - val_accuracy: 0.9890\n",
      "Epoch 18/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0913 - accuracy: 0.9753\n",
      "Epoch 00018: val_accuracy improved from 0.99048 to 0.99155, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0914 - accuracy: 0.9753 - val_loss: 0.0310 - val_accuracy: 0.9915\n",
      "Epoch 19/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0831 - accuracy: 0.9776\n",
      "Epoch 00019: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0830 - accuracy: 0.9776 - val_loss: 0.0372 - val_accuracy: 0.9894\n",
      "Epoch 20/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0739 - accuracy: 0.9797\n",
      "Epoch 00020: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0740 - accuracy: 0.9796 - val_loss: 0.0339 - val_accuracy: 0.9902\n",
      "Epoch 21/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0725 - accuracy: 0.9798\n",
      "Epoch 00021: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0725 - accuracy: 0.9798 - val_loss: 0.0330 - val_accuracy: 0.9910\n",
      "Epoch 22/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0792 - accuracy: 0.9786\n",
      "Epoch 00022: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0791 - accuracy: 0.9786 - val_loss: 0.0343 - val_accuracy: 0.9901\n",
      "Epoch 23/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0740 - accuracy: 0.9792\n",
      "Epoch 00023: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0740 - accuracy: 0.9792 - val_loss: 0.0326 - val_accuracy: 0.9912\n",
      "Epoch 24/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0727 - accuracy: 0.9796\n",
      "Epoch 00024: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0727 - accuracy: 0.9796 - val_loss: 0.0401 - val_accuracy: 0.9895\n",
      "Epoch 25/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0680 - accuracy: 0.9806\n",
      "Epoch 00025: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0681 - accuracy: 0.9806 - val_loss: 0.0331 - val_accuracy: 0.9904\n",
      "Epoch 26/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0695 - accuracy: 0.9806\n",
      "Epoch 00026: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0695 - accuracy: 0.9807 - val_loss: 0.0338 - val_accuracy: 0.9911\n",
      "Epoch 27/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0649 - accuracy: 0.9816\n",
      "Epoch 00027: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0650 - accuracy: 0.9816 - val_loss: 0.0299 - val_accuracy: 0.9911\n",
      "Epoch 28/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0692 - accuracy: 0.9806\n",
      "Epoch 00028: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0692 - accuracy: 0.9806 - val_loss: 0.0323 - val_accuracy: 0.9908\n",
      "Epoch 29/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0657 - accuracy: 0.9813\n",
      "Epoch 00029: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0657 - accuracy: 0.9813 - val_loss: 0.0366 - val_accuracy: 0.9896\n",
      "Epoch 30/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0656 - accuracy: 0.9826\n",
      "Epoch 00030: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0655 - accuracy: 0.9826 - val_loss: 0.0378 - val_accuracy: 0.9894\n",
      "Epoch 31/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 0.98 - ETA: 0s - loss: 0.0603 - accuracy: 0.9831\n",
      "Epoch 00031: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0602 - accuracy: 0.9831 - val_loss: 0.0400 - val_accuracy: 0.9900\n",
      "Epoch 32/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0611 - accuracy: 0.9831\n",
      "Epoch 00032: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0610 - accuracy: 0.9831 - val_loss: 0.0347 - val_accuracy: 0.9905\n",
      "Epoch 33/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0600 - accuracy: 0.9832\n",
      "Epoch 00033: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0599 - accuracy: 0.9832 - val_loss: 0.0355 - val_accuracy: 0.9900\n",
      "Epoch 34/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0542 - accuracy: 0.9848\n",
      "Epoch 00034: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0542 - accuracy: 0.9848 - val_loss: 0.0356 - val_accuracy: 0.9902\n",
      "Epoch 35/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0554 - accuracy: 0.9848\n",
      "Epoch 00035: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0557 - accuracy: 0.9847 - val_loss: 0.0339 - val_accuracy: 0.9911\n",
      "Epoch 36/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0556 - accuracy: 0.9844\n",
      "Epoch 00036: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0556 - accuracy: 0.9844 - val_loss: 0.0336 - val_accuracy: 0.9914\n",
      "Epoch 37/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0527 - accuracy: 0.9852\n",
      "Epoch 00037: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0530 - accuracy: 0.9852 - val_loss: 0.0452 - val_accuracy: 0.9886\n",
      "Epoch 38/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9834\n",
      "Epoch 00038: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0599 - accuracy: 0.9834 - val_loss: 0.0378 - val_accuracy: 0.9906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0518 - accuracy: 0.9854\n",
      "Epoch 00039: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0517 - accuracy: 0.9854 - val_loss: 0.0376 - val_accuracy: 0.9908\n",
      "Epoch 40/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0529 - accuracy: 0.9858\n",
      "Epoch 00040: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0528 - accuracy: 0.9859 - val_loss: 0.0378 - val_accuracy: 0.9905\n",
      "Epoch 41/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0519 - accuracy: 0.9859\n",
      "Epoch 00041: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0520 - accuracy: 0.9859 - val_loss: 0.0334 - val_accuracy: 0.9907\n",
      "Epoch 42/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0517 - accuracy: 0.9851\n",
      "Epoch 00042: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0516 - accuracy: 0.9851 - val_loss: 0.0375 - val_accuracy: 0.9914\n",
      "Epoch 43/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0531 - accuracy: 0.9853\n",
      "Epoch 00043: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0531 - accuracy: 0.9853 - val_loss: 0.0339 - val_accuracy: 0.9915\n",
      "Epoch 44/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0499 - accuracy: 0.9862\n",
      "Epoch 00044: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0498 - accuracy: 0.9862 - val_loss: 0.0327 - val_accuracy: 0.9908\n",
      "Epoch 45/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0491 - accuracy: 0.9862\n",
      "Epoch 00045: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0493 - accuracy: 0.9862 - val_loss: 0.0327 - val_accuracy: 0.9913\n",
      "Epoch 46/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0483 - accuracy: 0.9869\n",
      "Epoch 00046: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0484 - accuracy: 0.9869 - val_loss: 0.0406 - val_accuracy: 0.9886\n",
      "Epoch 47/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0501 - accuracy: 0.9863\n",
      "Epoch 00047: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0501 - accuracy: 0.9863 - val_loss: 0.0370 - val_accuracy: 0.9908\n",
      "Epoch 48/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9873 ETA\n",
      "Epoch 00048: val_accuracy did not improve from 0.99155\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0469 - accuracy: 0.9873 - val_loss: 0.0364 - val_accuracy: 0.9907\n",
      "Epoch 00048: early stopping\n",
      "Epoch 1/200\n",
      "   2/2100 [..............................] - ETA: 48:18 - loss: 3.0528 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0278s vs `on_train_batch_end` time: 2.7208s). Check your callbacks.\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.4902 - accuracy: 0.8576\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96286, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.4898 - accuracy: 0.8577 - val_loss: 0.1215 - val_accuracy: 0.9629\n",
      "Epoch 2/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.2460 - accuracy: 0.9318\n",
      "Epoch 00002: val_accuracy improved from 0.96286 to 0.97607, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.2460 - accuracy: 0.9318 - val_loss: 0.0816 - val_accuracy: 0.9761\n",
      "Epoch 3/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.2004 - accuracy: 0.9447\n",
      "Epoch 00003: val_accuracy improved from 0.97607 to 0.98190, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.2004 - accuracy: 0.9447 - val_loss: 0.0516 - val_accuracy: 0.9819\n",
      "Epoch 4/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.1754 - accuracy: 0.9513 ETA: 0s - loss: 0.1757 - accu\n",
      "Epoch 00004: val_accuracy improved from 0.98190 to 0.98357, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.1754 - accuracy: 0.9513 - val_loss: 0.0531 - val_accuracy: 0.9836\n",
      "Epoch 5/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.1604 - accuracy: 0.9561\n",
      "Epoch 00005: val_accuracy improved from 0.98357 to 0.98607, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.1604 - accuracy: 0.9562 - val_loss: 0.0460 - val_accuracy: 0.9861\n",
      "Epoch 6/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.9610\n",
      "Epoch 00006: val_accuracy improved from 0.98607 to 0.98798, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.1445 - accuracy: 0.9610 - val_loss: 0.0391 - val_accuracy: 0.9880\n",
      "Epoch 7/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.9662\n",
      "Epoch 00007: val_accuracy did not improve from 0.98798\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.1274 - accuracy: 0.9662 - val_loss: 0.0546 - val_accuracy: 0.9845\n",
      "Epoch 8/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.1143 - accuracy: 0.9684 ETA: 0s - los\n",
      "Epoch 00008: val_accuracy improved from 0.98798 to 0.98857, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1144 - accuracy: 0.9684 - val_loss: 0.0414 - val_accuracy: 0.9886\n",
      "Epoch 9/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.1185 - accuracy: 0.9666\n",
      "Epoch 00009: val_accuracy improved from 0.98857 to 0.99119, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.1185 - accuracy: 0.9666 - val_loss: 0.0311 - val_accuracy: 0.9912\n",
      "Epoch 10/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.1133 - accuracy: 0.9696\n",
      "Epoch 00010: val_accuracy did not improve from 0.99119\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1132 - accuracy: 0.9696 - val_loss: 0.0321 - val_accuracy: 0.9904\n",
      "Epoch 11/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.1021 - accuracy: 0.9718\n",
      "Epoch 00011: val_accuracy did not improve from 0.99119\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1023 - accuracy: 0.9718 - val_loss: 0.0376 - val_accuracy: 0.9901\n",
      "Epoch 12/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0975 - accuracy: 0.9736\n",
      "Epoch 00012: val_accuracy improved from 0.99119 to 0.99167, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0974 - accuracy: 0.9737 - val_loss: 0.0316 - val_accuracy: 0.9917\n",
      "Epoch 13/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0928 - accuracy: 0.9748\n",
      "Epoch 00013: val_accuracy did not improve from 0.99167\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0927 - accuracy: 0.9749 - val_loss: 0.0348 - val_accuracy: 0.9893\n",
      "Epoch 14/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9736\n",
      "Epoch 00014: val_accuracy did not improve from 0.99167\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0938 - accuracy: 0.9735 - val_loss: 0.0338 - val_accuracy: 0.9912\n",
      "Epoch 15/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0870 - accuracy: 0.9762\n",
      "Epoch 00015: val_accuracy improved from 0.99167 to 0.99226, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0870 - accuracy: 0.9762 - val_loss: 0.0285 - val_accuracy: 0.9923\n",
      "Epoch 16/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0837 - accuracy: 0.9773\n",
      "Epoch 00016: val_accuracy did not improve from 0.99226\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0836 - accuracy: 0.9773 - val_loss: 0.0322 - val_accuracy: 0.9912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.9766\n",
      "Epoch 00017: val_accuracy did not improve from 0.99226\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0882 - accuracy: 0.9766 - val_loss: 0.0272 - val_accuracy: 0.9913\n",
      "Epoch 18/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0802 - accuracy: 0.9778\n",
      "Epoch 00018: val_accuracy did not improve from 0.99226\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0801 - accuracy: 0.9779 - val_loss: 0.0364 - val_accuracy: 0.9899\n",
      "Epoch 19/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0814 - accuracy: 0.9773\n",
      "Epoch 00019: val_accuracy did not improve from 0.99226\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0815 - accuracy: 0.9773 - val_loss: 0.0325 - val_accuracy: 0.9902\n",
      "Epoch 20/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0746 - accuracy: 0.9796\n",
      "Epoch 00020: val_accuracy did not improve from 0.99226\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0745 - accuracy: 0.9796 - val_loss: 0.0296 - val_accuracy: 0.9918\n",
      "Epoch 21/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0744 - accuracy: 0.9800\n",
      "Epoch 00021: val_accuracy did not improve from 0.99226\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0745 - accuracy: 0.9800 - val_loss: 0.0556 - val_accuracy: 0.9854\n",
      "Epoch 22/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9813\n",
      "Epoch 00022: val_accuracy did not improve from 0.99226\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0686 - accuracy: 0.9813 - val_loss: 0.0387 - val_accuracy: 0.9898\n",
      "Epoch 23/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0694 - accuracy: 0.9804\n",
      "Epoch 00023: val_accuracy did not improve from 0.99226\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0693 - accuracy: 0.9804 - val_loss: 0.0299 - val_accuracy: 0.9907\n",
      "Epoch 24/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0646 - accuracy: 0.9821\n",
      "Epoch 00024: val_accuracy did not improve from 0.99226\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0646 - accuracy: 0.9821 - val_loss: 0.0353 - val_accuracy: 0.9904\n",
      "Epoch 25/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0663 - accuracy: 0.9810\n",
      "Epoch 00025: val_accuracy did not improve from 0.99226\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0663 - accuracy: 0.9810 - val_loss: 0.0341 - val_accuracy: 0.9900\n",
      "Epoch 26/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0624 - accuracy: 0.9838 ETA: 1s\n",
      "Epoch 00026: val_accuracy did not improve from 0.99226\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0624 - accuracy: 0.9838 - val_loss: 0.0342 - val_accuracy: 0.9906\n",
      "Epoch 27/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0675 - accuracy: 0.9816\n",
      "Epoch 00027: val_accuracy did not improve from 0.99226\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0675 - accuracy: 0.9816 - val_loss: 0.0323 - val_accuracy: 0.9910\n",
      "Epoch 28/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0581 - accuracy: 0.9838\n",
      "Epoch 00028: val_accuracy did not improve from 0.99226\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0580 - accuracy: 0.9838 - val_loss: 0.0327 - val_accuracy: 0.9907\n",
      "Epoch 29/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9825\n",
      "Epoch 00029: val_accuracy did not improve from 0.99226\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0616 - accuracy: 0.9825 - val_loss: 0.0280 - val_accuracy: 0.9917\n",
      "Epoch 30/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0600 - accuracy: 0.9831\n",
      "Epoch 00030: val_accuracy did not improve from 0.99226\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0600 - accuracy: 0.9831 - val_loss: 0.0351 - val_accuracy: 0.9911\n",
      "Epoch 31/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0570 - accuracy: 0.9848\n",
      "Epoch 00031: val_accuracy did not improve from 0.99226\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0575 - accuracy: 0.9847 - val_loss: 0.0359 - val_accuracy: 0.9911\n",
      "Epoch 32/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0590 - accuracy: 0.9840\n",
      "Epoch 00032: val_accuracy did not improve from 0.99226\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0591 - accuracy: 0.9840 - val_loss: 0.0335 - val_accuracy: 0.9920\n",
      "Epoch 33/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0569 - accuracy: 0.9842\n",
      "Epoch 00033: val_accuracy did not improve from 0.99226\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0569 - accuracy: 0.9843 - val_loss: 0.0329 - val_accuracy: 0.9918\n",
      "Epoch 34/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0503 - accuracy: 0.9861 ETA: 0s - loss: 0.0\n",
      "Epoch 00034: val_accuracy improved from 0.99226 to 0.99262, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0502 - accuracy: 0.9862 - val_loss: 0.0293 - val_accuracy: 0.9926\n",
      "Epoch 35/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0521 - accuracy: 0.9858\n",
      "Epoch 00035: val_accuracy improved from 0.99262 to 0.99333, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0521 - accuracy: 0.9857 - val_loss: 0.0265 - val_accuracy: 0.9933\n",
      "Epoch 36/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0561 - accuracy: 0.9848\n",
      "Epoch 00036: val_accuracy did not improve from 0.99333\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0561 - accuracy: 0.9848 - val_loss: 0.0309 - val_accuracy: 0.9924\n",
      "Epoch 37/200\n",
      "2094/2100 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 0.9851\n",
      "Epoch 00037: val_accuracy did not improve from 0.99333\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0517 - accuracy: 0.9851 - val_loss: 0.0310 - val_accuracy: 0.9921\n",
      "Epoch 38/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9868\n",
      "Epoch 00038: val_accuracy did not improve from 0.99333\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0459 - accuracy: 0.9868 - val_loss: 0.0314 - val_accuracy: 0.9927\n",
      "Epoch 39/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 0.9852\n",
      "Epoch 00039: val_accuracy did not improve from 0.99333\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0565 - accuracy: 0.9852 - val_loss: 0.0300 - val_accuracy: 0.9919\n",
      "Epoch 40/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0476 - accuracy: 0.9869\n",
      "Epoch 00040: val_accuracy improved from 0.99333 to 0.99357, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0477 - accuracy: 0.9868 - val_loss: 0.0265 - val_accuracy: 0.9936\n",
      "Epoch 41/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0486 - accuracy: 0.9857\n",
      "Epoch 00041: val_accuracy did not improve from 0.99357\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0486 - accuracy: 0.9857 - val_loss: 0.0351 - val_accuracy: 0.9912\n",
      "Epoch 42/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 0.9867\n",
      "Epoch 00042: val_accuracy did not improve from 0.99357\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0474 - accuracy: 0.9867 - val_loss: 0.0350 - val_accuracy: 0.9904\n",
      "Epoch 43/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0440 - accuracy: 0.9872\n",
      "Epoch 00043: val_accuracy did not improve from 0.99357\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0439 - accuracy: 0.9872 - val_loss: 0.0301 - val_accuracy: 0.9932\n",
      "Epoch 44/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0439 - accuracy: 0.9875\n",
      "Epoch 00044: val_accuracy did not improve from 0.99357\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0439 - accuracy: 0.9875 - val_loss: 0.0327 - val_accuracy: 0.9926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0462 - accuracy: 0.9865\n",
      "Epoch 00045: val_accuracy improved from 0.99357 to 0.99417, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0462 - accuracy: 0.9865 - val_loss: 0.0263 - val_accuracy: 0.9942\n",
      "Epoch 46/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0465 - accuracy: 0.9869\n",
      "Epoch 00046: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0464 - accuracy: 0.9869 - val_loss: 0.0329 - val_accuracy: 0.9926\n",
      "Epoch 47/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0446 - accuracy: 0.9874\n",
      "Epoch 00047: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0446 - accuracy: 0.9874 - val_loss: 0.0292 - val_accuracy: 0.9924\n",
      "Epoch 48/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9884\n",
      "Epoch 00048: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0449 - accuracy: 0.9884 - val_loss: 0.0302 - val_accuracy: 0.9926\n",
      "Epoch 49/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9878\n",
      "Epoch 00049: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0428 - accuracy: 0.9878 - val_loss: 0.0287 - val_accuracy: 0.9936\n",
      "Epoch 50/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0419 - accuracy: 0.9879\n",
      "Epoch 00050: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0419 - accuracy: 0.9879 - val_loss: 0.0297 - val_accuracy: 0.9933\n",
      "Epoch 51/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0419 - accuracy: 0.9885\n",
      "Epoch 00051: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0419 - accuracy: 0.9885 - val_loss: 0.0372 - val_accuracy: 0.9925\n",
      "Epoch 52/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0408 - accuracy: 0.9889\n",
      "Epoch 00052: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0408 - accuracy: 0.9889 - val_loss: 0.0340 - val_accuracy: 0.9926\n",
      "Epoch 53/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9893\n",
      "Epoch 00053: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0401 - accuracy: 0.9893 - val_loss: 0.0249 - val_accuracy: 0.9942\n",
      "Epoch 54/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0413 - accuracy: 0.9875\n",
      "Epoch 00054: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0412 - accuracy: 0.9875 - val_loss: 0.0299 - val_accuracy: 0.9939\n",
      "Epoch 55/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0393 - accuracy: 0.9889\n",
      "Epoch 00055: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0393 - accuracy: 0.9889 - val_loss: 0.0320 - val_accuracy: 0.9924\n",
      "Epoch 56/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9885\n",
      "Epoch 00056: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0410 - accuracy: 0.9885 - val_loss: 0.0336 - val_accuracy: 0.9908\n",
      "Epoch 57/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0404 - accuracy: 0.9892\n",
      "Epoch 00057: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0404 - accuracy: 0.9891 - val_loss: 0.0290 - val_accuracy: 0.9938\n",
      "Epoch 58/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9885\n",
      "Epoch 00058: val_accuracy did not improve from 0.99417\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0400 - accuracy: 0.9885 - val_loss: 0.0367 - val_accuracy: 0.9915\n",
      "Epoch 59/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9907\n",
      "Epoch 00059: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0317 - accuracy: 0.9907 - val_loss: 0.0281 - val_accuracy: 0.9938\n",
      "Epoch 60/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9915\n",
      "Epoch 00060: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0293 - accuracy: 0.9915 - val_loss: 0.0321 - val_accuracy: 0.9936\n",
      "Epoch 61/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0247 - accuracy: 0.9933\n",
      "Epoch 00061: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 0.0360 - val_accuracy: 0.9929\n",
      "Epoch 62/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9923\n",
      "Epoch 00062: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0269 - accuracy: 0.9923 - val_loss: 0.0339 - val_accuracy: 0.9937\n",
      "Epoch 63/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9921\n",
      "Epoch 00063: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0298 - accuracy: 0.9921 - val_loss: 0.0347 - val_accuracy: 0.9925\n",
      "Epoch 64/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0265 - accuracy: 0.9926\n",
      "Epoch 00064: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0265 - accuracy: 0.9926 - val_loss: 0.0318 - val_accuracy: 0.9931\n",
      "Epoch 65/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9926\n",
      "Epoch 00065: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.0315 - val_accuracy: 0.9938\n",
      "Epoch 66/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9922\n",
      "Epoch 00066: val_accuracy did not improve from 0.99417\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0279 - accuracy: 0.9922 - val_loss: 0.0324 - val_accuracy: 0.9933\n",
      "Epoch 67/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9935\n",
      "Epoch 00067: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0233 - accuracy: 0.9935 - val_loss: 0.0311 - val_accuracy: 0.9929\n",
      "Epoch 68/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.9939\n",
      "Epoch 00068: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0203 - accuracy: 0.9939 - val_loss: 0.0291 - val_accuracy: 0.9935\n",
      "Epoch 69/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9936\n",
      "Epoch 00069: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0241 - accuracy: 0.9936 - val_loss: 0.0339 - val_accuracy: 0.9926\n",
      "Epoch 70/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9946\n",
      "Epoch 00070: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0186 - accuracy: 0.9946 - val_loss: 0.0303 - val_accuracy: 0.9935\n",
      "Epoch 71/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0226 - accuracy: 0.9938\n",
      "Epoch 00071: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0226 - accuracy: 0.9938 - val_loss: 0.0312 - val_accuracy: 0.9931\n",
      "Epoch 72/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9940\n",
      "Epoch 00072: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 0.0316 - val_accuracy: 0.9930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9943\n",
      "Epoch 00073: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0197 - accuracy: 0.9943 - val_loss: 0.0324 - val_accuracy: 0.9929\n",
      "Epoch 74/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0206 - accuracy: 0.9942\n",
      "Epoch 00074: val_accuracy did not improve from 0.99417\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 0.0330 - val_accuracy: 0.9926\n",
      "Epoch 75/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9946\n",
      "Epoch 00075: val_accuracy did not improve from 0.99417\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0196 - accuracy: 0.9946 - val_loss: 0.0340 - val_accuracy: 0.9929\n",
      "Epoch 00075: early stopping\n",
      "Epoch 1/200\n",
      "   2/2100 [..............................] - ETA: 48:19 - loss: 2.9659 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0277s vs `on_train_batch_end` time: 2.7227s). Check your callbacks.\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.4845 - accuracy: 0.8564\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.97048, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 28s 13ms/step - loss: 0.4838 - accuracy: 0.8566 - val_loss: 0.0970 - val_accuracy: 0.9705\n",
      "Epoch 2/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.2491 - accuracy: 0.9306\n",
      "Epoch 00002: val_accuracy improved from 0.97048 to 0.98048, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.2490 - accuracy: 0.9306 - val_loss: 0.0591 - val_accuracy: 0.9805\n",
      "Epoch 3/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.2080 - accuracy: 0.9421\n",
      "Epoch 00003: val_accuracy improved from 0.98048 to 0.98381, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.2079 - accuracy: 0.9421 - val_loss: 0.0543 - val_accuracy: 0.9838\n",
      "Epoch 4/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.1756 - accuracy: 0.9510\n",
      "Epoch 00004: val_accuracy did not improve from 0.98381\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.1756 - accuracy: 0.9510 - val_loss: 0.0508 - val_accuracy: 0.9831\n",
      "Epoch 5/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.1611 - accuracy: 0.9556\n",
      "Epoch 00005: val_accuracy did not improve from 0.98381\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.1611 - accuracy: 0.9556 - val_loss: 0.0544 - val_accuracy: 0.9831\n",
      "Epoch 6/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.1460 - accuracy: 0.9600\n",
      "Epoch 00006: val_accuracy improved from 0.98381 to 0.98560, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1458 - accuracy: 0.9601 - val_loss: 0.0414 - val_accuracy: 0.9856\n",
      "Epoch 7/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.1388 - accuracy: 0.9628\n",
      "Epoch 00007: val_accuracy improved from 0.98560 to 0.98690, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1388 - accuracy: 0.9628 - val_loss: 0.0399 - val_accuracy: 0.9869\n",
      "Epoch 8/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.1220 - accuracy: 0.9658\n",
      "Epoch 00008: val_accuracy did not improve from 0.98690\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1220 - accuracy: 0.9658 - val_loss: 0.0426 - val_accuracy: 0.9860\n",
      "Epoch 9/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9689\n",
      "Epoch 00009: val_accuracy improved from 0.98690 to 0.98845, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1138 - accuracy: 0.9689 - val_loss: 0.0358 - val_accuracy: 0.9885\n",
      "Epoch 10/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.1137 - accuracy: 0.96 - ETA: 0s - loss: 0.1143 - accuracy: 0.9688\n",
      "Epoch 00010: val_accuracy improved from 0.98845 to 0.98905, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1143 - accuracy: 0.9688 - val_loss: 0.0340 - val_accuracy: 0.9890\n",
      "Epoch 11/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.1086 - accuracy: 0.9702\n",
      "Epoch 00011: val_accuracy improved from 0.98905 to 0.98917, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1088 - accuracy: 0.9701 - val_loss: 0.0337 - val_accuracy: 0.9892\n",
      "Epoch 12/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.1017 - accuracy: 0.9727\n",
      "Epoch 00012: val_accuracy did not improve from 0.98917\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.1016 - accuracy: 0.9728 - val_loss: 0.0325 - val_accuracy: 0.9887\n",
      "Epoch 13/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0986 - accuracy: 0.9736\n",
      "Epoch 00013: val_accuracy improved from 0.98917 to 0.98940, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0989 - accuracy: 0.9736 - val_loss: 0.0334 - val_accuracy: 0.9894\n",
      "Epoch 14/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0891 - accuracy: 0.9763\n",
      "Epoch 00014: val_accuracy improved from 0.98940 to 0.99012, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0890 - accuracy: 0.9763 - val_loss: 0.0295 - val_accuracy: 0.9901\n",
      "Epoch 15/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9735\n",
      "Epoch 00015: val_accuracy did not improve from 0.99012\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0919 - accuracy: 0.9735 - val_loss: 0.0424 - val_accuracy: 0.9870\n",
      "Epoch 16/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0855 - accuracy: 0.9762\n",
      "Epoch 00016: val_accuracy improved from 0.99012 to 0.99048, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0859 - accuracy: 0.9762 - val_loss: 0.0313 - val_accuracy: 0.9905\n",
      "Epoch 17/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0818 - accuracy: 0.9770\n",
      "Epoch 00017: val_accuracy improved from 0.99048 to 0.99095, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0820 - accuracy: 0.9770 - val_loss: 0.0286 - val_accuracy: 0.9910\n",
      "Epoch 18/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0795 - accuracy: 0.9788\n",
      "Epoch 00018: val_accuracy did not improve from 0.99095\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0795 - accuracy: 0.9788 - val_loss: 0.0383 - val_accuracy: 0.9894\n",
      "Epoch 19/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0795 - accuracy: 0.9785\n",
      "Epoch 00019: val_accuracy did not improve from 0.99095\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0795 - accuracy: 0.9786 - val_loss: 0.0374 - val_accuracy: 0.9881\n",
      "Epoch 20/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0803 - accuracy: 0.9790\n",
      "Epoch 00020: val_accuracy did not improve from 0.99095\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0802 - accuracy: 0.9790 - val_loss: 0.0378 - val_accuracy: 0.9894\n",
      "Epoch 21/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0731 - accuracy: 0.9799\n",
      "Epoch 00021: val_accuracy did not improve from 0.99095\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0731 - accuracy: 0.9799 - val_loss: 0.0318 - val_accuracy: 0.9910\n",
      "Epoch 22/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0745 - accuracy: 0.9791\n",
      "Epoch 00022: val_accuracy improved from 0.99095 to 0.99202, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0744 - accuracy: 0.9791 - val_loss: 0.0322 - val_accuracy: 0.9920\n",
      "Epoch 23/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0694 - accuracy: 0.9809\n",
      "Epoch 00023: val_accuracy did not improve from 0.99202\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0694 - accuracy: 0.9809 - val_loss: 0.0346 - val_accuracy: 0.9892\n",
      "Epoch 24/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0720 - accuracy: 0.9799\n",
      "Epoch 00024: val_accuracy did not improve from 0.99202\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0720 - accuracy: 0.9799 - val_loss: 0.0283 - val_accuracy: 0.9912\n",
      "Epoch 25/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0648 - accuracy: 0.9817\n",
      "Epoch 00025: val_accuracy did not improve from 0.99202\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0648 - accuracy: 0.9817 - val_loss: 0.0444 - val_accuracy: 0.9879\n",
      "Epoch 26/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0708 - accuracy: 0.9807\n",
      "Epoch 00026: val_accuracy did not improve from 0.99202\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0713 - accuracy: 0.9807 - val_loss: 0.0322 - val_accuracy: 0.9899\n",
      "Epoch 27/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0643 - accuracy: 0.9826 ETA: 0s - loss: 0.0641 - accuracy\n",
      "Epoch 00027: val_accuracy did not improve from 0.99202\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0644 - accuracy: 0.9826 - val_loss: 0.1414 - val_accuracy: 0.9608\n",
      "Epoch 28/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0636 - accuracy: 0.9820\n",
      "Epoch 00028: val_accuracy did not improve from 0.99202\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0636 - accuracy: 0.9820 - val_loss: 0.0318 - val_accuracy: 0.9910\n",
      "Epoch 29/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 0.9835\n",
      "Epoch 00029: val_accuracy did not improve from 0.99202\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0589 - accuracy: 0.9835 - val_loss: 0.0294 - val_accuracy: 0.9910\n",
      "Epoch 30/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9832\n",
      "Epoch 00030: val_accuracy did not improve from 0.99202\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0604 - accuracy: 0.9832 - val_loss: 0.0296 - val_accuracy: 0.9908\n",
      "Epoch 31/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0591 - accuracy: 0.9835\n",
      "Epoch 00031: val_accuracy did not improve from 0.99202\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0590 - accuracy: 0.9835 - val_loss: 0.0373 - val_accuracy: 0.9920\n",
      "Epoch 32/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0602 - accuracy: 0.9842\n",
      "Epoch 00032: val_accuracy did not improve from 0.99202\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0601 - accuracy: 0.9842 - val_loss: 0.0305 - val_accuracy: 0.9918\n",
      "Epoch 33/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0575 - accuracy: 0.9844\n",
      "Epoch 00033: val_accuracy did not improve from 0.99202\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0574 - accuracy: 0.9844 - val_loss: 0.0326 - val_accuracy: 0.9920\n",
      "Epoch 34/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0593 - accuracy: 0.9840\n",
      "Epoch 00034: val_accuracy did not improve from 0.99202\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0594 - accuracy: 0.9840 - val_loss: 0.0475 - val_accuracy: 0.9870\n",
      "Epoch 35/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0571 - accuracy: 0.9851\n",
      "Epoch 00035: val_accuracy did not improve from 0.99202\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0570 - accuracy: 0.9851 - val_loss: 0.0316 - val_accuracy: 0.9907\n",
      "Epoch 36/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0510 - accuracy: 0.9861\n",
      "Epoch 00036: val_accuracy did not improve from 0.99202\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0510 - accuracy: 0.9861 - val_loss: 0.0304 - val_accuracy: 0.9908\n",
      "Epoch 37/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0569 - accuracy: 0.9843\n",
      "Epoch 00037: val_accuracy did not improve from 0.99202\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0569 - accuracy: 0.9843 - val_loss: 0.0317 - val_accuracy: 0.9914\n",
      "Epoch 38/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0503 - accuracy: 0.9852\n",
      "Epoch 00038: val_accuracy did not improve from 0.99202\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0503 - accuracy: 0.9852 - val_loss: 0.0354 - val_accuracy: 0.9906\n",
      "Epoch 39/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9853\n",
      "Epoch 00039: val_accuracy did not improve from 0.99202\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0519 - accuracy: 0.9853 - val_loss: 0.0377 - val_accuracy: 0.9911\n",
      "Epoch 40/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9857\n",
      "Epoch 00040: val_accuracy improved from 0.99202 to 0.99238, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0514 - accuracy: 0.9857 - val_loss: 0.0295 - val_accuracy: 0.9924\n",
      "Epoch 41/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0478 - accuracy: 0.9859\n",
      "Epoch 00041: val_accuracy did not improve from 0.99238\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0478 - accuracy: 0.9859 - val_loss: 0.0365 - val_accuracy: 0.9910\n",
      "Epoch 42/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0423 - accuracy: 0.9891\n",
      "Epoch 00042: val_accuracy did not improve from 0.99238\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0422 - accuracy: 0.9891 - val_loss: 0.0289 - val_accuracy: 0.9924\n",
      "Epoch 43/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0381 - accuracy: 0.9894\n",
      "Epoch 00043: val_accuracy improved from 0.99238 to 0.99250, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0381 - accuracy: 0.9894 - val_loss: 0.0319 - val_accuracy: 0.9925\n",
      "Epoch 44/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9899\n",
      "Epoch 00044: val_accuracy did not improve from 0.99250\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0350 - accuracy: 0.9899 - val_loss: 0.0325 - val_accuracy: 0.9913\n",
      "Epoch 45/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9911 ETA: 0s - loss: 0\n",
      "Epoch 00045: val_accuracy did not improve from 0.99250\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0330 - accuracy: 0.9911 - val_loss: 0.0313 - val_accuracy: 0.9919\n",
      "Epoch 46/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0356 - accuracy: 0.9900\n",
      "Epoch 00046: val_accuracy did not improve from 0.99250\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0357 - accuracy: 0.9900 - val_loss: 0.0338 - val_accuracy: 0.9918\n",
      "Epoch 47/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9898\n",
      "Epoch 00047: val_accuracy did not improve from 0.99250\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0341 - accuracy: 0.9898 - val_loss: 0.0333 - val_accuracy: 0.9921\n",
      "Epoch 48/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9915\n",
      "Epoch 00048: val_accuracy did not improve from 0.99250\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0350 - accuracy: 0.9915 - val_loss: 0.0296 - val_accuracy: 0.9923\n",
      "Epoch 49/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9908\n",
      "Epoch 00049: val_accuracy did not improve from 0.99250\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0337 - accuracy: 0.9908 - val_loss: 0.0307 - val_accuracy: 0.9921\n",
      "Epoch 50/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9909\n",
      "Epoch 00050: val_accuracy did not improve from 0.99250\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0343 - accuracy: 0.9909 - val_loss: 0.0327 - val_accuracy: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0316 - accuracy: 0.9906\n",
      "Epoch 00051: val_accuracy did not improve from 0.99250\n",
      "2100/2100 [==============================] - 24s 11ms/step - loss: 0.0316 - accuracy: 0.9906 - val_loss: 0.0326 - val_accuracy: 0.9911\n",
      "Epoch 52/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9899\n",
      "Epoch 00052: val_accuracy did not improve from 0.99250\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0343 - accuracy: 0.9899 - val_loss: 0.0302 - val_accuracy: 0.9912\n",
      "Epoch 53/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0330 - accuracy: 0.9909\n",
      "Epoch 00053: val_accuracy did not improve from 0.99250\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0329 - accuracy: 0.9910 - val_loss: 0.0377 - val_accuracy: 0.9913\n",
      "Epoch 54/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0294 - accuracy: 0.9918\n",
      "Epoch 00054: val_accuracy did not improve from 0.99250\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0294 - accuracy: 0.9918 - val_loss: 0.0340 - val_accuracy: 0.9924\n",
      "Epoch 55/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9917 ETA: 0s - loss: 0.0289 - accuracy: \n",
      "Epoch 00055: val_accuracy did not improve from 0.99250\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0289 - accuracy: 0.9917 - val_loss: 0.0342 - val_accuracy: 0.9918\n",
      "Epoch 56/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0268 - accuracy: 0.9928\n",
      "Epoch 00056: val_accuracy improved from 0.99250 to 0.99286, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0268 - accuracy: 0.9928 - val_loss: 0.0314 - val_accuracy: 0.9929\n",
      "Epoch 57/200\n",
      "2094/2100 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9922\n",
      "Epoch 00057: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0275 - accuracy: 0.9923 - val_loss: 0.0343 - val_accuracy: 0.9927\n",
      "Epoch 58/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9928\n",
      "Epoch 00058: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0259 - accuracy: 0.9928 - val_loss: 0.0352 - val_accuracy: 0.9920\n",
      "Epoch 59/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9936 ETA: 0s - loss: 0.023\n",
      "Epoch 00059: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0236 - accuracy: 0.9936 - val_loss: 0.0307 - val_accuracy: 0.9925\n",
      "Epoch 60/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9936\n",
      "Epoch 00060: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0240 - accuracy: 0.9936 - val_loss: 0.0341 - val_accuracy: 0.9918\n",
      "Epoch 61/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9934\n",
      "Epoch 00061: val_accuracy did not improve from 0.99286\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0255 - accuracy: 0.9934 - val_loss: 0.0329 - val_accuracy: 0.9921\n",
      "Epoch 62/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0239 - accuracy: 0.9934\n",
      "Epoch 00062: val_accuracy improved from 0.99286 to 0.99298, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 0.0320 - val_accuracy: 0.9930\n",
      "Epoch 63/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9929\n",
      "Epoch 00063: val_accuracy did not improve from 0.99298\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0242 - accuracy: 0.9929 - val_loss: 0.0318 - val_accuracy: 0.9919\n",
      "Epoch 64/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9938\n",
      "Epoch 00064: val_accuracy did not improve from 0.99298\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0324 - val_accuracy: 0.9918\n",
      "Epoch 65/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9934\n",
      "Epoch 00065: val_accuracy improved from 0.99298 to 0.99321, saving model to best_model.h5\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0239 - accuracy: 0.9934 - val_loss: 0.0300 - val_accuracy: 0.9932\n",
      "Epoch 66/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9929\n",
      "Epoch 00066: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0254 - accuracy: 0.9929 - val_loss: 0.0321 - val_accuracy: 0.9926\n",
      "Epoch 67/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9944\n",
      "Epoch 00067: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0204 - accuracy: 0.9943 - val_loss: 0.0331 - val_accuracy: 0.9925\n",
      "Epoch 68/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9938\n",
      "Epoch 00068: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0238 - accuracy: 0.9938 - val_loss: 0.0326 - val_accuracy: 0.9923\n",
      "Epoch 69/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9932 ETA: 0s - loss: 0.0240 - accura\n",
      "Epoch 00069: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.0311 - val_accuracy: 0.9926\n",
      "Epoch 70/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.9939\n",
      "Epoch 00070: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 0.0329 - val_accuracy: 0.9920\n",
      "Epoch 71/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9935\n",
      "Epoch 00071: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.0332 - val_accuracy: 0.9921\n",
      "Epoch 72/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0228 - accuracy: 0.9935\n",
      "Epoch 00072: val_accuracy did not improve from 0.99321\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0228 - accuracy: 0.9935 - val_loss: 0.0343 - val_accuracy: 0.9925\n",
      "Epoch 73/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9946\n",
      "Epoch 00073: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0207 - accuracy: 0.9946 - val_loss: 0.0338 - val_accuracy: 0.9919\n",
      "Epoch 74/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9944 ETA: 0s - loss: 0.0202 - accuracy: \n",
      "Epoch 00074: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0204 - accuracy: 0.9943 - val_loss: 0.0339 - val_accuracy: 0.9919\n",
      "Epoch 75/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9947\n",
      "Epoch 00075: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.0336 - val_accuracy: 0.9923\n",
      "Epoch 76/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9945\n",
      "Epoch 00076: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0204 - accuracy: 0.9945 - val_loss: 0.0357 - val_accuracy: 0.9919\n",
      "Epoch 77/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9934\n",
      "Epoch 00077: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0232 - accuracy: 0.9934 - val_loss: 0.0355 - val_accuracy: 0.9917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/200\n",
      "2097/2100 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9951\n",
      "Epoch 00078: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.0350 - val_accuracy: 0.9921\n",
      "Epoch 79/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9951\n",
      "Epoch 00079: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.0358 - val_accuracy: 0.9921\n",
      "Epoch 80/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9945\n",
      "Epoch 00080: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.0363 - val_accuracy: 0.9924\n",
      "Epoch 81/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9947\n",
      "Epoch 00081: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 24s 12ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.0371 - val_accuracy: 0.9921\n",
      "Epoch 82/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9942\n",
      "Epoch 00082: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.0351 - val_accuracy: 0.9923\n",
      "Epoch 83/200\n",
      "2096/2100 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9946\n",
      "Epoch 00083: val_accuracy did not improve from 0.99321\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0190 - accuracy: 0.9946 - val_loss: 0.0353 - val_accuracy: 0.9921\n",
      "Epoch 84/200\n",
      "2095/2100 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9947\n",
      "Epoch 00084: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0195 - accuracy: 0.9947 - val_loss: 0.0346 - val_accuracy: 0.9925\n",
      "Epoch 85/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9950 ETA: 0s - loss: 0.016\n",
      "Epoch 00085: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 0.0368 - val_accuracy: 0.9920\n",
      "Epoch 86/200\n",
      "2094/2100 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.9950\n",
      "Epoch 00086: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0181 - accuracy: 0.9950 - val_loss: 0.0348 - val_accuracy: 0.9919\n",
      "Epoch 87/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9949\n",
      "Epoch 00087: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0204 - accuracy: 0.9949 - val_loss: 0.0348 - val_accuracy: 0.9918\n",
      "Epoch 88/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9945\n",
      "Epoch 00088: val_accuracy did not improve from 0.99321\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.0354 - val_accuracy: 0.9926\n",
      "Epoch 89/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9957\n",
      "Epoch 00089: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 0.0346 - val_accuracy: 0.9926\n",
      "Epoch 90/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9953\n",
      "Epoch 00090: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.0346 - val_accuracy: 0.9929\n",
      "Epoch 91/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9955\n",
      "Epoch 00091: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0167 - accuracy: 0.9955 - val_loss: 0.0349 - val_accuracy: 0.9931\n",
      "Epoch 92/200\n",
      "2100/2100 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9953\n",
      "Epoch 00092: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 0.0347 - val_accuracy: 0.9929\n",
      "Epoch 93/200\n",
      "2098/2100 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9947\n",
      "Epoch 00093: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.0347 - val_accuracy: 0.9924\n",
      "Epoch 94/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9948\n",
      "Epoch 00094: val_accuracy did not improve from 0.99321\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0177 - accuracy: 0.9948 - val_loss: 0.0342 - val_accuracy: 0.9929\n",
      "Epoch 95/200\n",
      "2099/2100 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9943\n",
      "Epoch 00095: val_accuracy did not improve from 0.99321\n",
      "2100/2100 [==============================] - 25s 12ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.0346 - val_accuracy: 0.9925\n",
      "Epoch 00095: early stopping\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import scipy\n",
    "first_col = True\n",
    "cross_fold = KFold(n_splits = 5, shuffle=True)\n",
    "for train_index, test_index in cross_fold.split(train['features']):\n",
    "    train_f = data1.iloc[:,1:]\n",
    "    train_l = data1.iloc[:,:1]\n",
    "    train_f = np.expand_dims(train_f, axis=(1, 0))\n",
    "    train_f = np.reshape(train_f, (-1, 28, 28, 1))\n",
    "    # Pad images with 0s\n",
    "    train_f      = np.pad(train_f, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "    \n",
    "    validation_f, validation_l = train_f[test_index], train_l.iloc[test_index]\n",
    "    train_f, train_l = train_f[train_index], train_l.iloc[train_index]\n",
    "    X_train, y_train = train_f, to_categorical(train_l)\n",
    "    X_validation, y_validation = validation_f, to_categorical(validation_l)\n",
    "\n",
    "    train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "    validation_generator = ImageDataGenerator().flow(X_validation, y_validation, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    # model itself\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), input_shape=(32,32,1)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('elu'))\n",
    "    model.add(layers.AveragePooling2D())\n",
    "\n",
    "    model.add(layers.Conv2D(filters=16, kernel_size=(3, 3)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('elu'))\n",
    "    model.add(layers.AveragePooling2D())\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dense(units=120))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('elu'))\n",
    "\n",
    "    model.add(layers.Dense(units=84))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('elu'))\n",
    "\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Dense(units=30))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('elu'))\n",
    "\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Dense(units=10, activation = 'softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(lr=0.002, \\\n",
    "        beta_1=0.9, beta_2=0.999, epsilon=1e-08), metrics=['accuracy'])\n",
    "\n",
    "    # model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.SGD(), metrics=['accuracy'])\n",
    "\n",
    "    # simple early stopping\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=TOL, verbose=VERBOSE, patience=N_ITER_NO_CHANGE)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=VERBOSE, save_best_only=True)\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "    \n",
    "    rlrop = ReduceLROnPlateau(monitor='accuracy', factor=0.5, patience=5, verbose=1)\n",
    "\n",
    "    # fit model\n",
    "    steps_per_epoch = X_train.shape[0]//BATCH_SIZE\n",
    "    validation_steps = X_validation.shape[0]//BATCH_SIZE\n",
    "    \n",
    "    # fit model and save the best\n",
    "    history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=MAX_EPOCHS, \n",
    "                        validation_data=validation_generator, validation_steps=validation_steps, \n",
    "                        shuffle=True, callbacks=[tensorboard, es, mc, rlrop])\n",
    "    saved_model = load_model('best_model.h5')\n",
    "    \n",
    "    probs = saved_model.predict(test['features'])\n",
    "#     cbr.fit(X=training_X_St.iloc[train_index], y=training_y[train_index], \n",
    "#         eval_set=(training_X_St.iloc[test_index], training_y[test_index]), use_best_model=True)\n",
    "    predict = probs.argmax(axis=1)\n",
    "    if first_col:\n",
    "        pr_values = np.array(predict, ndmin=2)\n",
    "        pr_values = np.transpose(pr_values)\n",
    "        first_col = False\n",
    "    else:\n",
    "        pr_values = np.insert(pr_values, -1, predict, axis=1)\n",
    "pr_values= scipy.stats.mode(pr_values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      2\n",
       "1      0\n",
       "2      9\n",
       "3      0\n",
       "4      3\n",
       "...   ..\n",
       "27995  9\n",
       "27996  7\n",
       "27997  3\n",
       "27998  9\n",
       "27999  2\n",
       "\n",
       "[28000 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting\n",
    "\n",
    "data3 = pd.DataFrame(pr_values[0])\n",
    "data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results\n",
    "data3.to_csv('E:/Python/data/digits/sample_submission24.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModeResult(mode=array([[2],\n",
       "       [0],\n",
       "       [9],\n",
       "       ...,\n",
       "       [3],\n",
       "       [9],\n",
       "       [2]], dtype=int64), count=array([[5],\n",
       "       [5],\n",
       "       [5],\n",
       "       ...,\n",
       "       [5],\n",
       "       [5],\n",
       "       [5]]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
